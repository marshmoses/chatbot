{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKAWeSK6NZsU8qqbJ/pROP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marshmoses/chatbot/blob/main/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFcYDy0pHaDU",
        "outputId": "0cdbaab2-c1a6-4943-aeb0-e86945bb720c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.13-py3-none-any.whl (810 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/810.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/810.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m809.0/810.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.29 (from langchain)\n",
            "  Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.33 (from langchain)\n",
            "  Downloading langchain_core-0.1.34-py3-none-any.whl (271 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.6/271.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.33-py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.6/86.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.33->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.13 langchain-community-0.0.29 langchain-core-0.1.34 langchain-text-splitters-0.0.1 langsmith-0.1.33 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.9.15 packaging-23.2 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "%pip install langchain\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install google.generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdHj5KzRIA99",
        "outputId": "6e60b829-cc27-4c86-8631-cbc884e8d506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google.generativeai in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.4.0 in /usr/local/lib/python3.10/dist-packages (from google.generativeai) (0.4.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from google.generativeai) (2.27.0)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google.generativeai) (2.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google.generativeai) (4.10.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google.generativeai) (3.20.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google.generativeai) (4.66.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.4.0->google.generativeai) (1.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google.generativeai) (1.63.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google.generativeai) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google.generativeai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth->google.generativeai) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth->google.generativeai) (4.9)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google.generativeai) (1.62.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google.generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth->google.generativeai) (0.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip  install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SG8blyS4IULZ",
        "outputId": "3426e2e7-3d21-420a-fd1b-3a89a00435e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.32.2-py2.py3-none-any.whl (8.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.10.0)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Installing collected packages: watchdog, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.42 pydeck-0.8.1b0 smmap-5.0.1 streamlit-1.32.2 watchdog-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install streamlit-extras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "li2qRP5jIkk0",
        "outputId": "0bc48961-677e-4528-b008-366eac1f4ec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit-extras\n",
            "  Downloading streamlit_extras-0.4.0-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.8/69.8 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints>=0.4 in /usr/local/lib/python3.10/dist-packages (from streamlit-extras) (0.4)\n",
            "Collecting htbuilder>=0.6.2 (from streamlit-extras)\n",
            "  Downloading htbuilder-0.6.2-py3-none-any.whl (12 kB)\n",
            "Collecting markdownlit>=0.0.5 (from streamlit-extras)\n",
            "  Downloading markdownlit-0.0.7-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: prometheus-client>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit-extras) (0.20.0)\n",
            "Requirement already satisfied: protobuf!=3.20.2 in /usr/local/lib/python3.10/dist-packages (from streamlit-extras) (3.20.3)\n",
            "Collecting st-annotated-text>=3.0.0 (from streamlit-extras)\n",
            "  Downloading st_annotated_text-4.0.1-py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: streamlit>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit-extras) (1.32.2)\n",
            "Collecting streamlit-camera-input-live>=0.2.0 (from streamlit-extras)\n",
            "  Downloading streamlit_camera_input_live-0.2.0-py3-none-any.whl (6.6 kB)\n",
            "Collecting streamlit-card>=0.0.4 (from streamlit-extras)\n",
            "  Downloading streamlit_card-1.0.0-py3-none-any.whl (680 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m680.8/680.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting streamlit-embedcode>=0.1.2 (from streamlit-extras)\n",
            "  Downloading streamlit_embedcode-0.1.2-py3-none-any.whl (3.5 kB)\n",
            "Collecting streamlit-faker>=0.0.2 (from streamlit-extras)\n",
            "  Downloading streamlit_faker-0.0.3-py3-none-any.whl (14 kB)\n",
            "Collecting streamlit-image-coordinates<0.2.0,>=0.1.1 (from streamlit-extras)\n",
            "  Downloading streamlit_image_coordinates-0.1.6-py3-none-any.whl (6.3 kB)\n",
            "Collecting streamlit-keyup>=0.1.9 (from streamlit-extras)\n",
            "  Downloading streamlit_keyup-0.2.3-py3-none-any.whl (7.4 kB)\n",
            "Collecting streamlit-toggle-switch>=1.0.2 (from streamlit-extras)\n",
            "  Downloading streamlit_toggle_switch-1.0.2-py3-none-any.whl (635 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m635.4/635.4 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting streamlit-vertical-slider>=2.5.5 (from streamlit-extras)\n",
            "  Downloading streamlit_vertical_slider-2.5.5-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from htbuilder>=0.6.2->streamlit-extras) (10.1.0)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from markdownlit>=0.0.5->streamlit-extras) (3.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from markdownlit>=0.0.5->streamlit-extras) (4.9.4)\n",
            "Collecting favicon (from markdownlit>=0.0.5->streamlit-extras)\n",
            "  Downloading favicon-0.7.0-py2.py3-none-any.whl (5.9 kB)\n",
            "Collecting pymdown-extensions (from markdownlit>=0.0.5->streamlit-extras)\n",
            "  Downloading pymdown_extensions-10.7.1-py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.8/250.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.0.0->streamlit-extras) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit>=1.0.0->streamlit-extras) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.0.0->streamlit-extras) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.0.0->streamlit-extras) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.0.0->streamlit-extras) (1.25.2)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.0.0->streamlit-extras) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.0.0->streamlit-extras) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.0.0->streamlit-extras) (9.4.0)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.0.0->streamlit-extras) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.0.0->streamlit-extras) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.0.0->streamlit-extras) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.0.0->streamlit-extras) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.0.0->streamlit-extras) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.0.0->streamlit-extras) (4.10.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.0.0->streamlit-extras) (3.1.42)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.0.0->streamlit-extras) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.0.0->streamlit-extras) (6.3.3)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.0.0->streamlit-extras) (4.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from streamlit-camera-input-live>=0.2.0->streamlit-extras) (3.1.3)\n",
            "Collecting faker (from streamlit-faker>=0.0.2->streamlit-extras)\n",
            "  Downloading Faker-24.4.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from streamlit-faker>=0.0.2->streamlit-extras) (3.7.1)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=1.0.0->streamlit-extras) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=1.0.0->streamlit-extras) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.0.0->streamlit-extras) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit>=1.0.0->streamlit-extras) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit>=1.0.0->streamlit-extras) (2023.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->streamlit-camera-input-live>=0.2.0->streamlit-extras) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=1.0.0->streamlit-extras) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=1.0.0->streamlit-extras) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=1.0.0->streamlit-extras) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=1.0.0->streamlit-extras) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=1.0.0->streamlit-extras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=1.0.0->streamlit-extras) (2.16.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from favicon->markdownlit>=0.0.5->streamlit-extras) (4.12.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras) (3.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from pymdown-extensions->markdownlit>=0.0.5->streamlit-extras) (6.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.7.0->favicon->markdownlit>=0.0.5->streamlit-extras) (2.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.0.0->streamlit-extras) (5.0.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.0.0->streamlit-extras) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.0.0->streamlit-extras) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.0.0->streamlit-extras) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.0.0->streamlit-extras) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=1.0.0->streamlit-extras) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<3,>=1.3.0->streamlit>=1.0.0->streamlit-extras) (1.16.0)\n",
            "Installing collected packages: pymdown-extensions, htbuilder, st-annotated-text, favicon, faker, streamlit-vertical-slider, streamlit-toggle-switch, streamlit-keyup, streamlit-image-coordinates, streamlit-embedcode, streamlit-card, streamlit-camera-input-live, streamlit-faker, markdownlit, streamlit-extras\n",
            "Successfully installed faker-24.4.0 favicon-0.7.0 htbuilder-0.6.2 markdownlit-0.0.7 pymdown-extensions-10.7.1 st-annotated-text-4.0.1 streamlit-camera-input-live-0.2.0 streamlit-card-1.0.0 streamlit-embedcode-0.1.2 streamlit-extras-0.4.0 streamlit-faker-0.0.3 streamlit-image-coordinates-0.1.6 streamlit-keyup-0.2.3 streamlit-toggle-switch-1.0.2 streamlit-vertical-slider-2.5.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pymongo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp3f6ahSIwwt",
        "outputId": "5f8cafb8-8625-4302-d9b9-cbdb80303aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymongo\n",
            "  Downloading pymongo-4.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (677 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.2/677.2 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.6.1 pymongo-4.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftzwJQsRJCe2",
        "outputId": "eb85898b-9cc9-41f1-e619-9eb700a55e58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78jsb75JJJHe",
        "outputId": "dc32716a-e5c4-4089-c095-cf166c62c6f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-2.6.1-py3-none-any.whl (163 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/163.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m153.6/163.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m407.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 sentence-transformers-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as palm\n",
        "#from dotenv import load_dotenv\n",
        "import streamlit as st\n",
        "from streamlit_extras.add_vertical_space import add_vertical_space\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.document_loaders import UnstructuredPDFLoader\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.embeddings import GooglePalmEmbeddings\n",
        "import os\n"
      ],
      "metadata": {
        "id": "5L2k70lzJcL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install --upgrade langchain"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGdh-0ZgKJdO",
        "outputId": "37a9c47a-88cc-4ff7-c358-4e9425f9aeba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.13)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.29 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.29)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.34)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.33)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.9.15)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import GooglePalm\n",
        "api_key='AIzaSyAPKvCTDopzRha-V6VMkDMuoaiVCc9YdQE'\n",
        "llms = GooglePalm(google_api_key=api_key,temperature=0.2)"
      ],
      "metadata": {
        "id": "K7FodzLJJ1g4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models=[\n",
        "     m for m in palm.list_models() if 'generateText' in m.supported_generation_methods\n",
        "]\n",
        "for m in models:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "PvXSTSy3KRdZ",
        "outputId": "3859c934-1e4d-4579-f36c-3f31bd3383b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/text-bison-001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=models[0]\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDl8sfUSKspH",
        "outputId": "9ab50eb2-24f4-413c-9d2a-cbdb0628e2c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(name='models/text-bison-001',\n",
              "      base_model_id='',\n",
              "      version='001',\n",
              "      display_name='PaLM 2 (Legacy)',\n",
              "      description='A legacy model that understands text and generates text as an output',\n",
              "      input_token_limit=8196,\n",
              "      output_token_limit=1024,\n",
              "      supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
              "      temperature=0.7,\n",
              "      top_p=0.95,\n",
              "      top_k=40)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt = '''\n",
        "summarize this paragraph and detail the main points.\n",
        "Text:'i am a student at the university of california, berkeley. i am studying computer science and i am in my third year. i am also a member of the computer science club and i am currently working on a project that involves machine learning. i am interested in pursuing a career in artificial intelligence and i am considering going to graduate school after i graduate. i am also interested in working at a tech company and i am considering applying for internships at companies like google and facebook. i am excited about the future and i am looking forward to the opportunities that lie ahead.'\n",
        "Summary:'in this paragraph, the author describes their academic background and interests. they are a student at the university of california, berkeley, studying computer science and in their third year. they are a member of the computer science club and working on a machine learning project. they are interested in pursuing a career in artificial intelligence, considering graduate school, and applying for internships at tech companies like google and facebook. they are excited about the future and looking forward to opportunities ahead.'\n",
        "Text:'i am a dog lover and i have two dogs of my own. i have a golden retriever named max and a labrador retriever named luna. i love taking them for walks and playing with them in the park. they are both very friendly and love to play with other dogs. i have had max for three years and luna for two years. they are both very loyal and loving pets and i cannot imagine my life without them.'\n",
        "'''\n"
      ],
      "metadata": {
        "id": "GWCPkqNrKc2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "completion = palm.generate_text(model=model,prompt=prompt,temperature=0.3, max_output_tokens=100)\n",
        "print(completion)"
      ],
      "metadata": {
        "id": "WuylmnLSKfgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pymongo import MongoClient\n",
        "\n",
        "# MongoDB connection\n",
        "client = MongoClient('mongodb+srv://mosesmacharia084:qKQkJdvQOMRXOiO9@cluster0.gcck2ys.mongodb.net/')\n",
        "db = client['ebay_watch_data']\n",
        "collection = db['refined_watches']\n",
        "\n",
        "# Retrieve a sample document from the collection\n",
        "sample_documents = collection.find().limit(9)\n",
        "\n",
        "print(\"Sample Documents:\")\n",
        "for doc in sample_documents:\n",
        "    print(doc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55_vzft9KykV",
        "outputId": "56af88c6-3bbf-4ee6-f180-c69a3050938c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Documents:\n",
            "{'_id': ObjectId('6601c7204c67eb695bf7adef'), 'input': 'Can you provide details about the ROLEX MENS DATEJUST BLUE DIAL 18K WHITE GOLD & STAINLESS STEEL WATCH?', 'output': 'The ROLEX MENS DATEJUST BLUE DIAL 18K WHITE GOLD & STAINLESS STEEL WATCH is Pre-owned and priced at $4199.95. You can find more details on the product page: https://www.ebay.com/itm/ROLEX-MENS-DATEJUST-BLUE-DIAL-18K-WHITE-GOLD-STAINLESS-STEEL-WATCH-/173854683740'}\n",
            "{'_id': ObjectId('6601c7204c67eb695bf7adf0'), 'input': 'Can you provide details about the Rolex Datejust Mens SS Stainless Steel & 18K White Gold Silver Dial 1601?', 'output': 'The Rolex Datejust Mens SS Stainless Steel & 18K White Gold Silver Dial 1601 is Pre-owned and priced at $3869.98. You can find more details on the product page: https://www.ebay.com/itm/Rolex-Datejust-Mens-SS-Stainless-Steel-18K-White-Gold-Silver-Dial-1601-/361708799266'}\n",
            "{'_id': ObjectId('6601c7214c67eb695bf7adf1'), 'input': 'Can you provide details about the ROLEX MENS DATEJUST GREEN DIAL 18K WHITE GOLD STEEL WATCH w/ JUBILEE BRACELET?', 'output': 'The ROLEX MENS DATEJUST GREEN DIAL 18K WHITE GOLD STEEL WATCH w/ JUBILEE BRACELET is Pre-owned and priced at $4199.95. You can find more details on the product page: https://www.ebay.com/itm/ROLEX-MENS-DATEJUST-GREEN-DIAL-18K-WHITE-GOLD-STEEL-WATCH-w-JUBILEE-BRACELET-/176068005601'}\n",
            "{'_id': ObjectId('6601c7214c67eb695bf7adf2'), 'input': 'Can you provide details about the Rolex Datejust 126300 Silver Oyster Bracelet with Silver Bezel?', 'output': 'The Rolex Datejust 126300 Silver Oyster Bracelet with Silver Bezel is New with tags and priced at $990.0. You can find more details on the product page: https://www.ebay.com/itm/Rolex-Datejust-126300-Silver-Oyster-Bracelet-Silver-Bezel-/386882694335'}\n",
            "{'_id': ObjectId('6601c7214c67eb695bf7adf3'), 'input': 'Can you provide details about the Serviced Vintage ROLEX Oyster 6082 Manual 34mm Patina Dial Men c.1948 #1193?', 'output': 'The Serviced Vintage ROLEX Oyster 6082 Manual 34mm Patina Dial Men c.1948 #1193 is Pre-owned and priced at $2300.0. You can find more details on the product page: https://www.ebay.com/itm/Serviced-Vintage-ROLEX-Oyster-6082-Manual-34mm-Patina-Dial-Men-c-1948-1193-/335318216858'}\n",
            "{'_id': ObjectId('6601c7214c67eb695bf7adf4'), 'input': \"Can you provide details about the Rolex Men's 36mm YG Fluted Bezel  DATEJUST QS Acrylic Crystal Ref 16013.#7481555?\", 'output': \"The Rolex Men's 36mm YG Fluted Bezel  DATEJUST QS Acrylic Crystal Ref 16013.#7481555 is Pre-owned and priced at $49.9. You can find more details on the product page: https://www.ebay.com/itm/Rolex-Mens-36mm-YG-Fluted-Bezel-DATEJUST-QS-Acrylic-Crystal-Ref-16013-7481555-/395293409425\"}\n",
            "{'_id': ObjectId('6601c7214c67eb695bf7adf5'), 'input': 'Can you provide details about the ROLEX MENS BLUE DIAL DATEJUST 18K WHITE GOLD & STAINLESS STEEL AUTHENTIC WATCH?', 'output': 'The ROLEX MENS BLUE DIAL DATEJUST 18K WHITE GOLD & STAINLESS STEEL AUTHENTIC WATCH is Pre-owned and priced at $4599.95. You can find more details on the product page: https://www.ebay.com/itm/ROLEX-MENS-BLUE-DIAL-DATEJUST-18K-WHITE-GOLD-STAINLESS-STEEL-AUTHENTIC-WATCH-/183520807230'}\n",
            "{'_id': ObjectId('6601c7214c67eb695bf7adf6'), 'input': 'Can you provide details about the ROLEX Explorer I 114270 Black F Number second hand mens?', 'output': 'The ROLEX Explorer I 114270 Black F Number second hand mens is Pre-owned and priced at $4872.0. You can find more details on the product page: https://www.ebay.com/itm/ROLEX-Explorer-114270-Black-F-Number-second-hand-mens-/145686564550'}\n",
            "{'_id': ObjectId('6601c7214c67eb695bf7adf7'), 'input': 'Can you provide details about the ROLEX Marconi 1950s size 30mm antique watch wristwatch manual winding（No,54）?', 'output': 'The ROLEX Marconi 1950s size 30mm antique watch wristwatch manual winding（No,54） is Pre-owned and priced at $20.5. You can find more details on the product page: https://www.ebay.com/itm/ROLEX-Marconi-1950s-size-30mm-antique-watch-wristwatch-manual-winding-No-54-/276393322408'}\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from pymongo import MongoClient\n",
        "from langchain.llms import GooglePalm\n",
        "\n",
        "# Connect to MongoDB database\n",
        "connection_string = 'mongodb+srv://mosesmacharia084:qKQkJdvQOMRXOiO9@cluster0.gcck2ys.mongodb.net/'\n",
        "database_name = \"ebay_watch_data\"\n",
        "collection_name = \"refined_watches\"\n",
        "\n",
        "# Connect to MongoDB\n",
        "client = MongoClient(connection_string)\n",
        "db = client[database_name]\n",
        "collection = db[collection_name]\n",
        "\n",
        "# Example query to MongoDB with limit of 10 documents\n",
        "query = {}  # Retrieve all documents\n",
        "documents = collection.find(query).limit(10)\n",
        "\n",
        "# Initialize the GooglePalm language model\n",
        "api_key='AIzaSyAPKvCTDopzRha-V6VMkDMuoaiVCc9YdQE'\n",
        "llms = GooglePalm(google_api_key=api_key,temperature=0.2)\n",
        "\n",
        "# Process documents with LangChain (e.g., generate text)\n",
        "for document in documents:\n",
        "    input_text = document[\"input\"]\n",
        "    generated_text = llms.predict(input_text)\n",
        "    print(f\"Input: {input_text}\")\n",
        "    print(f\"Generated Output: {generated_text}\")\n",
        "    print(\"Output from Database:\", document[\"output\"])\n",
        "    print()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "DiR8DwupYv0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pymongo import MongoClient\n",
        "from langchain.llms import GooglePalm\n",
        "\n",
        "# MongoDB connection parameters\n",
        "connection_string = 'mongodb+srv://mosesmacharia084:qKQkJdvQOMRXOiO9@cluster0.gcck2ys.mongodb.net/'\n",
        "database_name = \"ebay_watch_data\"\n",
        "refined_collection_name = \"refined_watches\"\n",
        "watch_ai_collection_name = \"watch_ai\"\n",
        "\n",
        "# Connect to MongoDB\n",
        "client = MongoClient(connection_string)\n",
        "db = client[database_name]\n",
        "refined_collection = db[refined_collection_name]\n",
        "watch_ai_collection = db[watch_ai_collection_name]\n",
        "\n",
        "# Initialize the GooglePalm language model\n",
        "api_key = 'AIzaSyAPKvCTDopzRha-V6VMkDMuoaiVCc9YdQE'\n",
        "llms = GooglePalm(google_api_key=api_key, temperature=0.2)\n",
        "\n",
        "# Retrieve documents from the existing collection\n",
        "query = {}  # Retrieve all documents\n",
        "documents = refined_collection.find(query)\n",
        "\n",
        "# Process documents with LangChain and store in watch_ai collection\n",
        "for document in documents:\n",
        "    input_text = document[\"input\"]\n",
        "    generated_text = llms.predict(input_text)\n",
        "\n",
        "    # Store the original data along with the generated text\n",
        "    document[\"generated_output\"] = generated_text\n",
        "\n",
        "    # Insert the document into the watch_ai collection\n",
        "    watch_ai_collection.insert_one(document)\n",
        "\n",
        "print(\"Data stored in the 'watch_ai' collection.\")\n"
      ],
      "metadata": {
        "id": "s09ZHaSfr3Gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#from sentence_transformers import SentenceTransformer\n",
        "#sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
        "\n",
        "#model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
        "#embeddings = model.encode(sentences)\n",
        "#print(embeddings)\n"
      ],
      "metadata": {
        "id": "RSZZBQfrZR-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from sentence_transformers import SentenceTransformer\n",
        "#sentences=['What is a price of a watch in a specific country?']\n",
        "#model=SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "##embeddings=model.encode(sentences)\n",
        "#print(embeddings)\n"
      ],
      "metadata": {
        "id": "T-tsakIVc9er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "few_shots= [\n",
        "    {\n",
        "        \"input\": \"Can you provide details about the ROLEX MENS DATEJUST BLUE DIAL 18K WHITE GOLD & STAINLESS STEEL WATCH?\",\n",
        "        \"generated_output\": \"**Model:** Rolex Datejust 126334\\n**Case:** 36mm stainless steel case with 18k white gold fluted bezel\\n**Dial:** Blue dial with applied gold hour markers and Roman numerals\\n**Hands:** Blued steel hands\\n**Movement:** Automatic Rolex Caliber 3235\\n**Power Reserve:** Approximately 70 hours\\n**Water Resistance:** 100 meters\\n**Strap:** Oyster bracelet with folding clasp\\n**Availability:** Available at authorized Rolex dealers\",\n",
        "        \"output_from_database\": \"The ROLEX MENS DATEJUST BLUE DIAL 18K WHITE GOLD & STAINLESS STEEL WATCH is Pre-owned and priced at $4199.95. You can find more details on the product page: https://www.ebay.com/itm/ROLEX-MENS-DATEJUST-BLUE-DIAL-18K-WHITE-GOLD-STAINLESS-STEEL-WATCH-/173854683740\"\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Can you provide details about the Rolex Datejust Mens SS Stainless Steel & 18K White Gold Silver Dial 1601?\",\n",
        "        \"generated_output\": \"**Model:** Rolex Datejust 1601\\n**Case:** Stainless steel and 18k white gold\\n**Bezel:** Fluted\\n**Dial:** Silver\\n**Hands:** Stick\\n**Markers:** Roman\\n**Date Indicator:** Cyclops lens over the date window at 3 o'clock\\n**Crystal:** Acrylic\\n**Movement:** Automatic Caliber 3035\\n**Power Reserve:** Approximately 48 hours\\n**Water Resistance:** 100 meters\\n**Dimensions:** 36mm diameter x 12mm thickness\\n**Lug Width:** 20mm\\n**Bracelet:** Stainless steel Jubilee bracelet with folding clasp\",\n",
        "        \"output_from_database\": \"The Rolex Datejust Mens SS Stainless Steel & 18K White Gold Silver Dial 1601 is Pre-owned and priced at $3869.98. You can find more details on the product page: https://www.ebay.com/itm/Rolex-Datejust-Mens-SS-Stainless-Steel-18K-White-Gold-Silver-Dial-1601-/361708799266\"\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Can you provide details about the ROLEX MENS DATEJUST GREEN DIAL 18K WHITE GOLD STEEL WATCH w/ JUBILEE BRACELET?\",\n",
        "        \"generated_output\": \"**Model:** 126334\\n**Diameter:** 41mm\\n**Case:** Stainless steel and 18k white gold\\n**Bezel:** Fluted\\n**Dial:** Green\\n**Hands:** Rhodium-plated\\n**Markers:** Roman numerals\\n**Crystal:** Sapphire\\n**Water Resistance:** 100 meters\\n**Movement:** Automatic\\n**Power Reserve:** Approximately 70 hours\\n**Strap:** Jubilee bracelet with folding clasp\",\n",
        "        \"output_from_database\": \"The ROLEX MENS DATEJUST GREEN DIAL 18K WHITE GOLD STEEL WATCH w/ JUBILEE BRACELET is Pre-owned and priced at $4199.95. You can find more details on the product page: https://www.ebay.com/itm/ROLEX-MENS-DATEJUST-GREEN-DIAL-18K-WHITE-GOLD-STEEL-WATCH-w-JUBILEE-BRACELET-/176068005601\"\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Can you provide details about the Rolex Datejust 126300 Silver Oyster Bracelet with Silver Bezel?\",\n",
        "        \"generated_output\": \"The Rolex Datejust 126300 is a stainless steel watch with a silver dial and a silver bezel. It is powered by the Rolex Caliber 3235 movement, which has a power reserve of approximately 70 hours. The watch has a water resistance of 100 meters.\",\n",
        "        \"output_from_database\": \"The Rolex Datejust 126300 Silver Oyster Bracelet with Silver Bezel is New with tags and priced at $990.0. You can find more details on the product page: https://www.ebay.com/itm/Rolex-Datejust-126300-Silver-Oyster-Bracelet-Silver-Bezel-/386882694335\"\n",
        "    },\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "TvSvtc34FwLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_vectorize = [''.join(example.values()) for example in few_shots]\n",
        "print(to_vectorize)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjEnobEUIXxF",
        "outputId": "682b6363-847a-4594-dd78-381638223885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Can you provide details about the ROLEX MENS DATEJUST BLUE DIAL 18K WHITE GOLD & STAINLESS STEEL WATCH?**Model:** Rolex Datejust 126334\\n**Case:** 36mm stainless steel case with 18k white gold fluted bezel\\n**Dial:** Blue dial with applied gold hour markers and Roman numerals\\n**Hands:** Blued steel hands\\n**Movement:** Automatic Rolex Caliber 3235\\n**Power Reserve:** Approximately 70 hours\\n**Water Resistance:** 100 meters\\n**Strap:** Oyster bracelet with folding clasp\\n**Availability:** Available at authorized Rolex dealersThe ROLEX MENS DATEJUST BLUE DIAL 18K WHITE GOLD & STAINLESS STEEL WATCH is Pre-owned and priced at $4199.95. You can find more details on the product page: https://www.ebay.com/itm/ROLEX-MENS-DATEJUST-BLUE-DIAL-18K-WHITE-GOLD-STAINLESS-STEEL-WATCH-/173854683740', \"Can you provide details about the Rolex Datejust Mens SS Stainless Steel & 18K White Gold Silver Dial 1601?**Model:** Rolex Datejust 1601\\n**Case:** Stainless steel and 18k white gold\\n**Bezel:** Fluted\\n**Dial:** Silver\\n**Hands:** Stick\\n**Markers:** Roman\\n**Date Indicator:** Cyclops lens over the date window at 3 o'clock\\n**Crystal:** Acrylic\\n**Movement:** Automatic Caliber 3035\\n**Power Reserve:** Approximately 48 hours\\n**Water Resistance:** 100 meters\\n**Dimensions:** 36mm diameter x 12mm thickness\\n**Lug Width:** 20mm\\n**Bracelet:** Stainless steel Jubilee bracelet with folding claspThe Rolex Datejust Mens SS Stainless Steel & 18K White Gold Silver Dial 1601 is Pre-owned and priced at $3869.98. You can find more details on the product page: https://www.ebay.com/itm/Rolex-Datejust-Mens-SS-Stainless-Steel-18K-White-Gold-Silver-Dial-1601-/361708799266\", 'Can you provide details about the ROLEX MENS DATEJUST GREEN DIAL 18K WHITE GOLD STEEL WATCH w/ JUBILEE BRACELET?**Model:** 126334\\n**Diameter:** 41mm\\n**Case:** Stainless steel and 18k white gold\\n**Bezel:** Fluted\\n**Dial:** Green\\n**Hands:** Rhodium-plated\\n**Markers:** Roman numerals\\n**Crystal:** Sapphire\\n**Water Resistance:** 100 meters\\n**Movement:** Automatic\\n**Power Reserve:** Approximately 70 hours\\n**Strap:** Jubilee bracelet with folding claspThe ROLEX MENS DATEJUST GREEN DIAL 18K WHITE GOLD STEEL WATCH w/ JUBILEE BRACELET is Pre-owned and priced at $4199.95. You can find more details on the product page: https://www.ebay.com/itm/ROLEX-MENS-DATEJUST-GREEN-DIAL-18K-WHITE-GOLD-STEEL-WATCH-w-JUBILEE-BRACELET-/176068005601', 'Can you provide details about the Rolex Datejust 126300 Silver Oyster Bracelet with Silver Bezel?The Rolex Datejust 126300 is a stainless steel watch with a silver dial and a silver bezel. It is powered by the Rolex Caliber 3235 movement, which has a power reserve of approximately 70 hours. The watch has a water resistance of 100 meters.The Rolex Datejust 126300 Silver Oyster Bracelet with Silver Bezel is New with tags and priced at $990.0. You can find more details on the product page: https://www.ebay.com/itm/Rolex-Datejust-126300-Silver-Oyster-Bracelet-Silver-Bezel-/386882694335']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "\n",
        "# Load pre-trained SentenceTransformer model\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Embed and vectorize text data\n",
        "for example in few_shots:\n",
        "    concatenated_text = ' '.join(example.values())\n",
        "    embedding = model.encode([concatenated_text])[0]\n",
        "    # Store the embedding in MongoDB\n",
        "    example[\"embedding\"] = embedding.tolist()\n",
        "    collection.insert_one(example)\n"
      ],
      "metadata": {
        "id": "NJXLo6fHqgMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo import MongoClient\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# MongoDB connection parameters\n",
        "connection_string = 'mongodb+srv://mosesmacharia084:qKQkJdvQOMRXOiO9@cluster0.gcck2ys.mongodb.net/'\n",
        "database_name = \"ebay_watch_data\"\n",
        "watch_ai_collection_name = \"watch_ai\"\n",
        "watch_vec_collection_name = \"watch_vec\"\n",
        "\n",
        "# Initialize SentenceTransformer model\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Connect to MongoDB\n",
        "client = MongoClient(connection_string)\n",
        "db = client[database_name]\n",
        "watch_ai_collection = db[watch_ai_collection_name]\n",
        "watch_vec_collection = db[watch_vec_collection_name]\n",
        "\n",
        "# Retrieve documents from watch_ai collection\n",
        "documents = watch_ai_collection.find({})\n",
        "\n",
        "# Embed and vectorize text data\n",
        "for document in documents:\n",
        "    concatenated_text = ' '.join([str(value) for value in document.values()])\n",
        "    embedding = model.encode([concatenated_text])[0]\n",
        "    # Store the embedding in MongoDB\n",
        "    document[\"embedding\"] = embedding.tolist()\n",
        "    # Insert the document with embedding into the watch_vec collection\n",
        "    watch_vec_collection.insert_one(document)\n"
      ],
      "metadata": {
        "id": "N6txUFFA0MXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import SemanticSimilarityExampleSelector\n",
        "SemanticSimilarityExampleSelector(\n",
        "    vectorstore=vectorscore,\n",
        "    k=2,\n",
        ")"
      ],
      "metadata": {
        "id": "M6UfXaf4LmA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo import MongoClient\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# MongoDB connection string\n",
        "connection_string = 'mongodb+srv://mosesmacharia084:qKQkJdvQOMRXOiO9@cluster0.gcck2ys.mongodb.net/'\n",
        "\n",
        "# Database and collection names\n",
        "database_name = \"ebay_watch_data\"\n",
        "collection_name = \"watch_vec\"\n",
        "\n",
        "# Initialize SentenceTransformer model\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Connect to MongoDB\n",
        "client = MongoClient(connection_string)\n",
        "db = client[database_name]\n",
        "collection = db[collection_name]\n",
        "\n",
        "# Retrieve embeddings from MongoDB\n",
        "embeddings = []\n",
        "for document in collection.find({}, {\"_id\": 0, \"embedding\": 1}):\n",
        "    embeddings.append(document[\"embedding\"])\n",
        "\n",
        "# Convert embeddings to numpy array\n",
        "embeddings = np.array(embeddings)\n",
        "\n",
        "# Define a function to calculate cosine similarity\n",
        "def calculate_similarity(query_embedding, embeddings):\n",
        "    similarities = cosine_similarity([query_embedding], embeddings)\n",
        "    return similarities[0]\n",
        "\n",
        "# Example query\n",
        "query = \"Can you provide details about the Rolex Datejust 126300 Silver Oyster Bracelet with Silver Bezel?\"\n",
        "\n",
        "# Encode the query\n",
        "query_embedding = model.encode([query])[0]\n",
        "\n",
        "# Calculate similarity scores\n",
        "similarities = calculate_similarity(query_embedding, embeddings)\n",
        "\n",
        "# Find the index of the most similar document\n",
        "most_similar_index = np.argmax(similarities)\n",
        "most_similar_document = collection.find_one({\"embedding\": embeddings[most_similar_index].tolist()})\n",
        "\n",
        "# Print the most similar document\n",
        "print(\"Most similar document:\")\n",
        "print(most_similar_document)\n",
        "\n",
        "# Close MongoDB connection\n",
        "client.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RO8hxsJ94QzV",
        "outputId": "e21d1b72-394c-478b-f45f-f91cb412ad7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most similar document:\n",
            "{'_id': ObjectId('6601c7284c67eb695bf7ae49'), 'input': 'Can you provide details about the Rolex Datejust 36mm Gold and Silver Oyster Bracelet Gold Diamond Bezel 116243?', 'output': 'The Rolex Datejust 36mm Gold and Silver Oyster Bracelet Gold Diamond Bezel 116243 is Pre-owned and priced at $10499.0. You can find more details on the product page: https://www.ebay.com/itm/Rolex-Datejust-36mm-Gold-and-Silver-Oyster-Bracelet-Gold-Diamond-Bezel-116243-/204695929510', 'generated_output': '**Model:** Rolex Datejust 36mm\\n\\n**Reference:** 116243\\n\\n**Case:** Stainless steel case with 18k yellow gold fluted bezel set with 10 diamonds (total 0.18 ct.)\\n\\n**Dial:** Silver dial with 18k yellow gold Roman numerals and stick markers\\n\\n**Hands:** Blued steel hands\\n\\n**Movement:** Automatic Caliber 3135\\n\\n**Power Reserve:** Approximately 48 hours\\n\\n**Bracelet:** 18k yellow gold Oyster bracelet with deployant clasp\\n\\n**Water Resistance:** 100 meters\\n\\n**Dimensions:** 36mm diameter x 12mm thickness\\n\\n**Retail Price:** $11,550\\n\\nThe Rolex Datejust 36mm Gold and Silver Oyster Bracelet Gold Diamond Bezel 116243 is a classic and elegant timepiece that is perfect for everyday wear. The stainless steel case and 18k yellow gold fluted bezel give the watch a luxurious look, while the silver dial and 18k yellow gold Roman numerals and stick markers provide a touch of sophistication. The watch is powered by the automatic Caliber 3135 movement, which has a power reserve of approximately 48 hours. The watch is also water resistant to 100 meters, making it suitable for everyday wear. The 18k yellow gold Oyster bracelet with deployant clasp provides a comfortable and secure fit. The Rolex Datejust 36mm Gold and Silver Oyster Bracelet Gold Diamond Bezel 116243 is a timeless and stylish watch that is sure to turn heads wherever you go.', 'embedding': [-0.06197664886713028, 0.030273880809545517, 0.018330387771129608, 0.022435637190937996, -0.09720170497894287, 0.04814669489860535, 0.06383524090051651, 0.06783336400985718, -0.04659899324178696, -0.06403785943984985, -0.031509265303611755, -0.04089463874697685, 0.05869375541806221, -0.016690142452716827, -0.033298615366220474, -0.04455583170056343, 0.12902598083019257, -0.016990436241030693, -0.05722271651029587, 0.049718257039785385, -3.848374035442248e-05, -0.07008643448352814, -0.013468959368765354, -0.034372713416814804, -0.049180202186107635, 0.037090979516506195, 0.0021857810206711292, -0.041459910571575165, -0.032754458487033844, -0.03688913956284523, -0.007983840070664883, 0.09894872456789017, 0.03912895545363426, 0.009027956053614616, -0.012304474599659443, 0.0019262665882706642, 0.019986087456345558, 0.0026503957342356443, -0.047281861305236816, -0.01729942485690117, -0.0006625703535974026, 0.03473621606826782, -0.0038941046223044395, 0.03509090840816498, -0.01594442129135132, 0.028989024460315704, -0.0004086327098775655, 0.00909424014389515, -0.050956301391124725, 0.08567062765359879, -0.00041324159246869385, -0.045233096927404404, 0.03265111520886421, -0.004708772525191307, 0.06368321180343628, 0.03629688918590546, -0.04877888411283493, -0.07339991629123688, 0.04521403834223747, 0.0045508090406656265, 0.055654000490903854, -0.0439976304769516, -0.06565267592668533, 0.025411294773221016, 0.005212130956351757, 0.03790540620684624, 0.010436199605464935, -0.08521053194999695, -0.038598280400037766, -0.07932578027248383, 0.06551070511341095, 0.009834583848714828, 0.02191021852195263, 0.01795937865972519, 0.05512741208076477, 0.09504701942205429, 0.12009160965681076, -0.053924884647130966, 0.016945643350481987, -0.07623431831598282, -0.06553157418966293, -0.02423742227256298, -0.024906201288104057, 0.02250780165195465, 0.057108424603939056, 0.019903400912880898, 0.049682535231113434, 0.03133343905210495, 0.021776868030428886, -0.0038278065621852875, 0.06727701425552368, 0.013327623717486858, -0.010160096921026707, -0.03101411834359169, -0.009567774832248688, -0.005797838792204857, 0.003712339559569955, 0.09793315082788467, -0.005485485307872295, 0.06603547930717468, 0.055572375655174255, 0.005345979239791632, 0.0410197451710701, 0.023364929482340813, 0.016825390979647636, -0.0376109778881073, -0.030424410477280617, 0.07145202159881592, -0.008200318552553654, 0.0009157673339359462, -0.041982054710388184, -0.04191702604293823, -0.03804658725857735, -0.04489483684301376, -0.024379562586545944, 0.021449150517582893, -0.05301873758435249, 0.047222256660461426, 0.10451842844486237, -0.02666480466723442, 0.10223346203565598, 0.019998040050268173, -0.018370406702160835, -0.0010961703956127167, -0.08789219707250595, 0.033693913370370865, -0.06955627351999283, 6.543727258478125e-33, -0.06257960200309753, 0.007266998291015625, 0.028039949014782906, -0.014959859661757946, 0.0350971519947052, -0.04696260020136833, 0.023984214290976524, 0.022523850202560425, -0.02030159719288349, 0.05441616103053093, -0.010090717114508152, 0.03497886285185814, -0.010794774629175663, -0.0420139916241169, 0.008339551277458668, -0.04409773647785187, 0.0502922423183918, 0.006937970407307148, 0.003140282817184925, -0.034854140132665634, 0.014876841567456722, -0.028646554797887802, -0.05807396024465561, 0.030672268941998482, -0.023131337016820908, 0.07511599361896515, 0.05532291904091835, 0.028005924075841904, 0.05712592601776123, 0.03926078975200653, -0.01962326280772686, -0.07883019000291824, 0.0444573238492012, -0.027302179485559464, -0.001165448222309351, 0.033608224242925644, -0.04378804191946983, -0.049751486629247665, 0.020226623862981796, -0.0542464442551136, 0.0055022225715219975, 0.02693004161119461, -0.06563004106283188, -0.04355883225798607, -0.021997151896357536, -0.07044647634029388, 0.03219413012266159, 0.06867142021656036, 0.0844455361366272, 0.02131602168083191, -0.06596020609140396, 0.03147329390048981, 0.038163281977176666, -0.027095049619674683, -0.02826577238738537, -0.002165441866964102, 0.006438562646508217, -0.015005707740783691, 0.016926592215895653, -0.030835628509521484, 0.044572614133358, 0.04368021339178085, 0.0054435813799500465, 0.08514893800020218, 0.048522017896175385, 0.10958335548639297, 0.013971391133964062, -0.062155015766620636, -0.05759946256875992, -0.052813638001680374, -0.09140003472566605, 0.025704678148031235, 0.10957716405391693, -0.01435451116412878, -0.03595992922782898, -0.04216642677783966, 0.03140214830636978, -0.0893988087773323, -0.010159878060221672, -0.031873319298028946, -0.020626887679100037, 0.05427219718694687, 0.03117532469332218, 0.03494331240653992, -0.034625809639692307, -0.053370945155620575, 0.013205108232796192, -0.01672356389462948, -0.033381566405296326, 0.004293890669941902, 0.02725939080119133, -0.07780671864748001, -0.10646788775920868, 0.04696500301361084, -0.021329427137970924, -4.6964951915105026e-33, 0.005532522220164537, -0.06539195030927658, 0.05526690185070038, -0.013486132025718689, 0.09392531216144562, -0.04545213282108307, 0.04141652211546898, 0.12389910966157913, 0.049334559589624405, 0.02385926991701126, 0.06523999571800232, -0.0051422459073364735, -0.027906356379389763, -0.00022424821509048343, -0.026035044342279434, 0.07410313189029694, -0.022168755531311035, -0.0023083582054823637, 0.021248865872621536, -0.04840506240725517, 0.029293827712535858, 0.0874197855591774, -0.01588737778365612, 0.03974517062306404, -0.09205736964941025, 0.08581305295228958, 0.006887233816087246, 0.02624514326453209, 0.0042175184935331345, 0.0614689402282238, -0.0706256777048111, -0.07424470037221909, 0.027613097801804543, 0.05632553994655609, -0.08285384625196457, -0.06808043271303177, 0.04726310819387436, 0.013949551619589329, 0.047445911914110184, -0.020150698721408844, -0.03014182671904564, -0.006977321580052376, 0.024155916646122932, 0.05408019199967384, 0.04899873211979866, 0.010008014738559723, 0.07500884681940079, -0.0017709886888042092, 0.0732835978269577, 0.03403808921575546, -0.050850946456193924, -0.014816377311944962, 0.031021784991025925, 0.08641999959945679, -0.04594157636165619, 0.05320486053824425, 0.05105762556195259, -0.012449989095330238, 0.0642295703291893, -0.024252915754914284, 0.08213607221841812, 0.07272151112556458, 0.03987168148159981, 0.007784633431583643, 0.06613698601722717, 0.03423936665058136, -0.0405421145260334, -0.0048316954635083675, -0.07485970109701157, -0.02023705653846264, -0.036456234753131866, -0.03427816182374954, -0.05426677316427231, -0.10193761438131332, 0.02160632610321045, -0.019048653542995453, -0.010461816564202309, 0.00827700924128294, -0.06411843001842499, -0.0008254069834947586, 0.02975546009838581, 0.004161922726780176, 0.013958786614239216, 0.07944613695144653, 0.017913032323122025, 0.0014268266968429089, 0.05550188943743706, 0.09307543933391571, -0.06113836169242859, -0.005066706798970699, -0.10194195061922073, 0.011217755265533924, -0.0018819032702594995, -0.002586686983704567, 0.03513263538479805, -5.884400522404576e-08, -0.03584104776382446, 0.06630809605121613, -0.0375249870121479, -0.05587131902575493, 0.03988724201917648, -0.037898801267147064, -0.012537417002022266, -0.013739046640694141, 0.011721581220626831, 0.05368902161717415, 0.0435619093477726, -0.08987375348806381, -0.09441117942333221, -0.10053163021802902, -0.06864156574010849, -0.07208118587732315, -0.12872302532196045, 0.024571701884269714, -0.06046559289097786, -0.06347627937793732, 0.08033343404531479, -0.0030479601118713617, 0.14700040221214294, -0.12670184671878815, -0.062340155243873596, 0.006302167661488056, -0.10881559550762177, 0.07808160781860352, -0.021075792610645294, 0.061419159173965454, -0.02670733630657196, -0.0036330746952444315, 0.07760076224803925, -0.04425400495529175, -0.04716823250055313, -0.03445562347769737, -0.0950222909450531, 0.07355625927448273, 0.06969333440065384, 0.0019760611467063427, 0.016671914607286453, -0.09697382152080536, -0.10176050662994385, 0.09890241175889969, 0.08043680340051651, -0.021667810156941414, -0.041500650346279144, -0.026646891608834267, 0.022962091490626335, 0.02140367589890957, -0.023458993062376976, -0.01188366673886776, -0.03991417586803436, -0.07829470932483673, -0.04664480686187744, 0.07235085219144821, 0.0250185988843441, 0.0679229125380516, 0.0062543549574911594, 0.08703494817018509, 0.030455462634563446, -0.13216917216777802, -0.04815993085503578, 0.037173081189394]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install graphene"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "e9kIq4cLM0Uc",
        "outputId": "b0f024fa-0f82-4364-9bef-e894a60c054a"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphene in /usr/local/lib/python3.10/dist-packages (3.3)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene)\n",
            "  Using cached graphql_core-3.2.3-py3-none-any.whl (202 kB)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene) (3.2.0)\n",
            "Requirement already satisfied: aniso8601<10,>=8 in /usr/local/lib/python3.10/dist-packages (from graphene) (9.0.1)\n",
            "Installing collected packages: graphql-core\n",
            "  Attempting uninstall: graphql-core\n",
            "    Found existing installation: graphql-core 2.3.2\n",
            "    Uninstalling graphql-core-2.3.2:\n",
            "      Successfully uninstalled graphql-core-2.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask-graphql 2.0.1 requires graphql-core<3,>=2.1, but you have graphql-core 3.2.3 which is incompatible.\n",
            "graphql-server-core 1.2.0 requires graphql-core<3,>=2.3, but you have graphql-core 3.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed graphql-core-3.2.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "graphql"
                ]
              },
              "id": "a294080c09b749099f3a14cd3931cd69"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade graphql-core\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQFcvfprOn0R",
        "outputId": "fbb2c757-88f8-49d8-c096-6c0879d9b2fd"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphql-core in /usr/local/lib/python3.10/dist-packages (3.2.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install graphql-core==3.1.5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "bGnYWKyUQUR4",
        "outputId": "07f4b39d-b428-4b92-9eb3-225ef70c10b2"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting graphql-core==3.1.5\n",
            "  Using cached graphql_core-3.1.5-py3-none-any.whl (188 kB)\n",
            "Installing collected packages: graphql-core\n",
            "  Attempting uninstall: graphql-core\n",
            "    Found existing installation: graphql-core 3.2.3\n",
            "    Uninstalling graphql-core-3.2.3:\n",
            "      Successfully uninstalled graphql-core-3.2.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask-graphql 2.0.1 requires graphql-core<3,>=2.1, but you have graphql-core 3.1.5 which is incompatible.\n",
            "graphql-relay 3.2.0 requires graphql-core<3.3,>=3.2, but you have graphql-core 3.1.5 which is incompatible.\n",
            "graphql-server-core 1.2.0 requires graphql-core<3,>=2.3, but you have graphql-core 3.1.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed graphql-core-3.1.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "graphql"
                ]
              },
              "id": "74a1eb93fe3343e38059fa053b2979ee"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Flask-GraphQL\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        },
        "id": "Xu1X2AuINxLZ",
        "outputId": "44ce28da-5092-493a-8555-c53a34c9d106"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Flask-GraphQL\n",
            "  Downloading Flask-GraphQL-2.0.1.tar.gz (6.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting graphql-core<3,>=2.1 (from Flask-GraphQL)\n",
            "  Downloading graphql_core-2.3.2-py2.py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.5/252.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flask>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from Flask-GraphQL) (2.2.5)\n",
            "Collecting graphql-server-core<2,>=1.1 (from Flask-GraphQL)\n",
            "  Downloading graphql-server-core-1.2.0.tar.gz (7.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask>=0.7.0->Flask-GraphQL) (3.0.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask>=0.7.0->Flask-GraphQL) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask>=0.7.0->Flask-GraphQL) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask>=0.7.0->Flask-GraphQL) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from graphql-core<3,>=2.1->Flask-GraphQL) (1.16.0)\n",
            "Requirement already satisfied: promise<3,>=2.3 in /usr/local/lib/python3.10/dist-packages (from graphql-core<3,>=2.1->Flask-GraphQL) (2.3)\n",
            "Collecting rx<2,>=1.6 (from graphql-core<3,>=2.1->Flask-GraphQL)\n",
            "  Downloading Rx-1.6.3.tar.gz (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.5/97.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask>=0.7.0->Flask-GraphQL) (2.1.5)\n",
            "Building wheels for collected packages: Flask-GraphQL, graphql-server-core, rx\n",
            "  Building wheel for Flask-GraphQL (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Flask-GraphQL: filename=Flask_GraphQL-2.0.1-py3-none-any.whl size=6361 sha256=bfb20f417546ff3285a1a1c3249ced15aa11eb5b4de49868d416e5d1f1b9eef1\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/7d/8a/e1d0f22c4670ea75abcf1ad7fd9a25c8dd81d3e3a1068d28f9\n",
            "  Building wheel for graphql-server-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for graphql-server-core: filename=graphql_server_core-1.2.0-py2.py3-none-any.whl size=7544 sha256=b5f181b3fea3e4819276094aab5541604e45d6e6e620cd745815f94273555546\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/1a/f1/e4f5eb63352773523b34168ace93d8687c29230a140b2478db\n",
            "  Building wheel for rx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rx: filename=Rx-1.6.3-py2.py3-none-any.whl size=182329 sha256=61f5d635e367f30187839ba58a76cb6fc6bccde590eca3de45d0bde36dc4ba1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/3b/0a/2c436ed1854fccc8961f1ae4ba739ef7900b47ba8188be4b67\n",
            "Successfully built Flask-GraphQL graphql-server-core rx\n",
            "Installing collected packages: rx, graphql-core, graphql-server-core, Flask-GraphQL\n",
            "  Attempting uninstall: graphql-core\n",
            "    Found existing installation: graphql-core 3.2.3\n",
            "    Uninstalling graphql-core-3.2.3:\n",
            "      Successfully uninstalled graphql-core-3.2.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "graphene 3.3 requires graphql-core<3.3,>=3.1, but you have graphql-core 2.3.2 which is incompatible.\n",
            "graphql-relay 3.2.0 requires graphql-core<3.3,>=3.2, but you have graphql-core 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Flask-GraphQL-2.0.1 graphql-core-2.3.2 graphql-server-core-1.2.0 rx-1.6.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "graphql"
                ]
              },
              "id": "a3eb0f01248546b89198d1364253a0c0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymongo\n",
        "from langchain.llms import GooglePalm\n",
        "from langchain.vectorstores import MongoDBAtlasVectorSearch\n",
        "from langchain.prompts import PromptTemplate\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# MongoDB connection parameters\n",
        "connection_string ='mongodb+srv://mosesmacharia084:qKQkJdvQOMRXOiO9@cluster0.gcck2ys.mongodb.net/'\n",
        "database_name = \"ebay_watch_data\"\n",
        "collection_name = \"watch_vec\"\n",
        "\n",
        "# Connect to MongoDB\n",
        "client = pymongo.MongoClient(connection_string)\n",
        "db = client[database_name]\n",
        "collection = db[collection_name]\n",
        "\n",
        "# Initialize SentenceTransformer model\n",
        "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Retrieve embeddings from MongoDB\n",
        "embeddings = []\n",
        "for document in collection.find({}, {\"_id\": 0, \"embedding\": 1}):\n",
        "    embeddings.append(document[\"embedding\"])\n",
        "\n",
        "# Convert embeddings to numpy array\n",
        "embeddings = np.array(embeddings)\n",
        "\n",
        "# Initialize GooglePalm language model\n",
        "api_key='AIzaSyAPKvCTDopzRha-V6VMkDMuoaiVCc9YdQE'\n",
        "llms = GooglePalm(google_api_key=api_key,temperature=0.2)\n",
        "\n",
        "# Define the prompt template\n",
        "prompt_template = PromptTemplate(name=\"input\", description=\"output\")\n",
        "\n",
        "# Initialize MongoDBAtlasVectorSearch with the embedded collection\n",
        "vector_search = MongoDBAtlasVectorSearch(collection)\n",
        "\n",
        "def execute_mongodb_query(prompt_text):\n",
        "    # Process the prompt with LangChain to generate the query\n",
        "    query = llms.prompt(prompt_text, prompt_template)\n",
        "\n",
        "    # Execute the similarity search against MongoDB\n",
        "    search_results = vector_search.similarity_search_with_score(query)\n",
        "\n",
        "    # Retrieve and process the results\n",
        "    processed_results = [result for result in search_results]\n",
        "\n",
        "    return processed_results\n",
        "\n",
        "# Example of querying MongoDB using LangChain\n",
        "prompt_text = \"Retrieve documents similar to 'Rolex watches'.\"\n",
        "query_results = execute_mongodb_query(prompt_text)\n",
        "print(query_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "H5nahtGMDhW9",
        "outputId": "bcb7bb13-1d03-4082-c78b-be53e7e5b7e3"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'input_variables'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-168-68cb8b2022c4>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Define the prompt template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mprompt_template\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPromptTemplate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"output\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Initialize MongoDBAtlasVectorSearch with the embedded collection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/load/serializable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lc_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/v1/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \"\"\"\n\u001b[1;32m    338\u001b[0m         \u001b[0;31m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__pydantic_self__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalidation_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/v1/main.py\u001b[0m in \u001b[0;36mvalidate_model\u001b[0;34m(model, input_data, cls)\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrorWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mROOT_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/prompts/base.py\u001b[0m in \u001b[0;36mvalidate_variable_names\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidate_variable_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;34m\"\"\"Validate variable names do not include restricted names.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"stop\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_variables\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             raise ValueError(\n\u001b[1;32m    134\u001b[0m                 \u001b[0;34m\"Cannot have an input variable named 'stop', as it is used internally,\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'input_variables'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymongo\n",
        "from langchain.llms import GooglePalm\n",
        "from langchain.vectorstores import MongoDBAtlasVectorSearch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "# MongoDB connection parameters\n",
        "connection_string ='mongodb+srv://mosesmacharia084:qKQkJdvQOMRXOiO9@cluster0.gcck2ys.mongodb.net/'\n",
        "database_name = \"ebay_watch_data\"\n",
        "collection_name = \"watch_vec\"\n",
        "\n",
        "# Connect to MongoDB\n",
        "client = pymongo.MongoClient(connection_string)\n",
        "db = client[database_name]\n",
        "collection = db[collection_name]\n",
        "\n",
        "# Initialize SentenceTransformer model\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Retrieve embeddings from MongoDB\n",
        "embeddings = []\n",
        "for document in collection.find({}, {\"_id\": 0, \"embedding\": 1}):\n",
        "    embeddings.append(document[\"embedding\"])\n",
        "\n",
        "# Convert embeddings to numpy array\n",
        "embeddings = np.array(embeddings)\n",
        "\n",
        "# Initialize GooglePalm language model\n",
        "api_key='AIzaSyAPKvCTDopzRha-V6VMkDMuoaiVCc9YdQE'\n",
        "llms = GooglePalm(google_api_key=api_key, temperature=0.2)\n",
        "\n",
        "# Initialize MongoDBAtlasVectorSearch with the embedded collection\n",
        "# Initialize MongoDBAtlasVectorSearch with the embedded collection and embedding model\n",
        "vector_search = MongoDBAtlasVectorSearch(collection, embedding_model)\n",
        "\n",
        "\n",
        "def execute_mongodb_query(query_text):\n",
        "    # Encode the query text using SentenceTransformer\n",
        "    query_embedding =model.encode([query_text])[0]\n",
        "\n",
        "    # Execute the similarity search against MongoDB\n",
        "    similarities = vector_search.similarity_search_with_score(query_embedding,embeddings)\n",
        "\n",
        "    # Retrieve and process the results\n",
        "    processed_results = [result for result in search_results]\n",
        "\n",
        "    return processed_results\n",
        "\n",
        "def generate_text_from_results(results):\n",
        "    # Concatenate the results into a single text\n",
        "    result_text = '\\n'.join(result['text'] for result in results)\n",
        "\n",
        "    # Generate text continuation using GooglePalm\n",
        "    generated_text = llms.predict(result_text)\n",
        "\n",
        "    return generated_text\n",
        "\n",
        "# Example of querying MongoDB and generating text using GooglePalm\n",
        "query_text = input(\"Enter your query: \")\n",
        "query_results = execute_mongodb_query(query_text)\n",
        "generated_text = generate_text_from_results(query_results)\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "dMRzsxxbS017",
        "outputId": "144e9150-0b97-4adf-847e-20af99c8e21b"
      },
      "execution_count": 188,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your query: Rolex\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'SentenceTransformer' object has no attribute 'embed_query'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-188-a2c751029122>\u001b[0m in \u001b[0;36m<cell line: 60>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# Example of querying MongoDB and generating text using GooglePalm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mquery_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter your query: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mquery_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute_mongodb_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0mgenerated_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_text_from_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-188-a2c751029122>\u001b[0m in \u001b[0;36mexecute_mongodb_query\u001b[0;34m(query_text)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# Execute the similarity search against MongoDB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0msimilarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvector_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity_search_with_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_embedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# Retrieve and process the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/mongodb_atlas.py\u001b[0m in \u001b[0;36msimilarity_search_with_score\u001b[0;34m(self, query, k, pre_filter, post_filter_pipeline)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0mmost\u001b[0m \u001b[0msimilar\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \"\"\"\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         docs = self._similarity_search_with_score(\n\u001b[1;32m    246\u001b[0m             \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1686\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'SentenceTransformer' object has no attribute 'embed_query'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "orB1iYAOS0UV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pymongo\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# MongoDB connection parameters\n",
        "connection_string ='mongodb+srv://mosesmacharia084:qKQkJdvQOMRXOiO9@cluster0.gcck2ys.mongodb.net/'\n",
        "database_name = \"ebay_watch_data\"\n",
        "collection_name = \"watch_vec\"\n",
        "\n",
        "# Connect to MongoDB\n",
        "client = pymongo.MongoClient(connection_string)\n",
        "db = client[database_name]\n",
        "collection = db[collection_name]\n",
        "\n",
        "# Initialize SentenceTransformer model\n",
        "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Retrieve embeddings from MongoDB\n",
        "embeddings = []\n",
        "for document in collection.find({}, {\"_id\": 0, \"embedding\": 1}):\n",
        "    embeddings.append(document[\"embedding\"])\n",
        "\n",
        "# Convert embeddings to numpy array\n",
        "embeddings = np.array(embeddings)\n",
        "\n",
        "# Define a function to calculate cosine similarity\n",
        "def execute_mongodb_query(query_text):\n",
        "    # Encode the query text using Sentence Transformers\n",
        "    query_embedding = embedding_model.encode([query_text])[0]\n",
        "\n",
        "    # Calculate similarity scores\n",
        "    similarities = calculate_similarity(query_embedding, embeddings)\n",
        "\n",
        "    # Find the index of the most similar document\n",
        "    most_similar_index = np.argmax(similarities)\n",
        "\n",
        "    # Check if the index is within the range of documents in the collection\n",
        "    if most_similar_index < collection.count_documents({}):\n",
        "        most_similar_document = collection.find().skip(1).limit(1)\n",
        "        return most_similar_document[0] if most_similar_document.count(5) > 0 else None\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Example of querying MongoDB using Sentence Transformers\n",
        "query_text = \"Rolex watches\"\n",
        "query_result = execute_mongodb_query(query_text)\n",
        "print(query_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "XZHWnUO4W6B_",
        "outputId": "b5bb4894-3f14-456b-cd7f-d17e0ea120d0"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Cursor' object has no attribute 'count'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-193-b9f30b7a1fe3>\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Example of querying MongoDB using Sentence Transformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mquery_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Rolex watches\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mquery_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute_mongodb_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-193-b9f30b7a1fe3>\u001b[0m in \u001b[0;36mexecute_mongodb_query\u001b[0;34m(query_text)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmost_similar_index\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mcollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mmost_similar_document\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmost_similar_document\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmost_similar_document\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Cursor' object has no attribute 'count'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymongo\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# MongoDB connection parameters\n",
        "connection_string ='mongodb+srv://mosesmacharia084:qKQkJdvQOMRXOiO9@cluster0.gcck2ys.mongodb.net/'\n",
        "database_name = \"ebay_watch_data\"\n",
        "collection_name = \"watch_vec\"\n",
        "\n",
        "# Connect to MongoDB\n",
        "client = pymongo.MongoClient(connection_string)\n",
        "db = client[database_name]\n",
        "collection = db[collection_name]\n",
        "\n",
        "# Initialize SentenceTransformer model\n",
        "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Retrieve embeddings from MongoDB\n",
        "embeddings = []\n",
        "for document in collection.find({}, {\"_id\": 0, \"embedding\": 1}):\n",
        "    embeddings.append(document[\"embedding\"])\n",
        "\n",
        "# Convert embeddings to numpy array\n",
        "embeddings = np.array(embeddings)\n",
        "\n",
        "# Define a function to calculate cosine similarity\n",
        "def calculate_similarity(query_embedding, embeddings):\n",
        "    similarities = cosine_similarity([query_embedding], embeddings)\n",
        "    return similarities[0]\n",
        "\n",
        "def execute_mongodb_query(query_text):\n",
        "    # Encode the query text using Sentence Transformers\n",
        "    query_embedding = embedding_model.encode([query_text])[0]\n",
        "\n",
        "    # Calculate similarity scores\n",
        "    similarities = calculate_similarity(query_embedding, embeddings)\n",
        "\n",
        "    # Find the index of the most similar document\n",
        "    most_similar_index = np.argmax(similarities)\n",
        "\n",
        "    # Check if the index is within the range of documents in the collection\n",
        "    if most_similar_index < collection.count_documents({}):\n",
        "        most_similar_document = collection.find().skip(most_similar_index).limit(1)\n",
        "        return most_similar_document[0] if most_similar_document.count() > 0 else None\n",
        "    else:\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "YCMziARvYrYF"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example query text\n",
        "query_text = \"Rolex watches\"\n",
        "\n",
        "# Execute the MongoDB query\n",
        "query_result = execute_mongodb_query(query_text)\n",
        "\n",
        "# Print the result\n",
        "print(query_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "iBDZvkg0Za8Y",
        "outputId": "b63657f1-d4c2-49ce-f7bd-ba00a2220fb8"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "skip must be an integer",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-195-b5529d363e09>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Execute the MongoDB query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mquery_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute_mongodb_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Print the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-194-1d68b0d99692>\u001b[0m in \u001b[0;36mexecute_mongodb_query\u001b[0;34m(query_text)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Check if the index is within the range of documents in the collection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmost_similar_index\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mcollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mmost_similar_document\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmost_similar_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmost_similar_document\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmost_similar_document\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymongo/cursor.py\u001b[0m in \u001b[0;36mskip\u001b[0;34m(self, skip)\u001b[0m\n\u001b[1;32m    627\u001b[0m         \"\"\"\n\u001b[1;32m    628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"skip must be an integer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mskip\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"skip must be >= 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: skip must be an integer"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymongo\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# MongoDB connection parameters\n",
        "connection_string ='mongodb+srv://mosesmacharia084:qKQkJdvQOMRXOiO9@cluster0.gcck2ys.mongodb.net/'\n",
        "database_name = \"ebay_watch_data\"\n",
        "collection_name = \"watch_vec\"\n",
        "\n",
        "# Connect to MongoDB\n",
        "client = pymongo.MongoClient(connection_string)\n",
        "db = client[database_name]\n",
        "collection = db[collection_name]\n",
        "\n",
        "# Initialize SentenceTransformer model\n",
        "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Retrieve embeddings from MongoDB\n",
        "embeddings = []\n",
        "for document in collection.find({}, {\"_id\": 0, \"embedding\": 1}):\n",
        "    embeddings.append(document[\"embedding\"])\n",
        "\n",
        "# Convert embeddings to numpy array\n",
        "embeddings = np.array(embeddings)\n",
        "\n",
        "# Define a function to calculate cosine similarity\n",
        "def execute_mongodb_query(query_text):\n",
        "    # Encode the query text using Sentence Transformers\n",
        "    query_embedding = embedding_model.encode([query_text])[0]\n",
        "\n",
        "    # Calculate similarity scores\n",
        "    similarities = calculate_similarity(query_embedding, embeddings)\n",
        "\n",
        "    # Find the index of the most similar document\n",
        "    most_similar_index = np.argmax(similarities)\n",
        "\n",
        "    # Skip documents if necessary\n",
        "    skip_count = 0\n",
        "    for document in collection.find():\n",
        "        if skip_count == most_similar_index:\n",
        "            return document\n",
        "        skip_count += 1\n",
        "\n",
        "    return None\n",
        "\n",
        "# Example query\n",
        "query_text = \"Rolex watches\"\n",
        "query_result = execute_mongodb_query(query_text)\n",
        "print(query_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eWLGeskaNmk",
        "outputId": "534ee113-0967-47c5-b395-7ada19f35aac"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'_id': ObjectId('6601c7244c67eb695bf7ae16'), 'input': 'Can you provide details about the rolex 118139?', 'output': 'The rolex 118139 is Pre-owned and priced at $17500.0. You can find more details on the product page: https://www.ebay.com/itm/rolex-118139-/126118190527', 'generated_output': 'The Rolex 118139 is a stainless steel and yellow gold Datejust 36 watch with a black dial and fluted bezel. It was first introduced in 2018 and is still in production today. The watch is powered by the Rolex Caliber 3235, a self-winding movement with a power reserve of approximately 70 hours.\\n\\nThe 118139 has a 36mm case and a 20mm lug width. It comes on a Jubilee bracelet with a folding clasp. The watch is water resistant to 100 meters.\\n\\nThe 118139 is a versatile and stylish watch that can be worn for any occasion. It is perfect for everyday wear, but it is also dressy enough to be worn for special events. The watch is also a good investment, as it is sure to retain its value over time.\\n\\nHere are some of the key features of the Rolex 118139:\\n\\n* Stainless steel and yellow gold construction\\n* Black dial with fluted bezel\\n* Rolex Caliber 3235 movement\\n* Power reserve of approximately 70 hours\\n* 36mm case\\n* 20mm lug width\\n* Jubilee bracelet with folding clasp\\n* Water resistant to 100 meters\\n\\nIf you are looking for a stylish and versatile watch that is sure to turn heads, the Rolex 118139 is a great option. It is a classic watch that will look good for years to come.', 'embedding': [-0.09219326823949814, 0.03474142402410507, -0.004295808728784323, 0.050468768924474716, -0.05092066153883934, 0.0720185711979866, 0.0704561248421669, 0.026219911873340607, -0.04345523938536644, -0.04362823814153671, -0.07657650858163834, 0.04117220267653465, 0.009717247448861599, 0.0099331671372056, -0.0743945837020874, -0.07195249944925308, 0.1056930348277092, -0.02096528187394142, -0.03750550001859665, 0.03682825714349747, -0.018386999145150185, -0.09245433658361435, 0.028329316526651382, 0.004730380605906248, -0.05073879286646843, -0.0091565465554595, 0.019675113260746002, -0.026587245985865593, 0.025321880355477333, -0.041974108666181564, 0.001652366598136723, 0.046014294028282166, -0.009754217229783535, -0.011886505410075188, -0.004548423923552036, 0.03841531276702881, 0.05592814087867737, -0.045889098197221756, -0.04631917551159859, -0.039201997220516205, 0.06384690850973129, 0.0630299299955368, 0.03245881572365761, 0.04629490152001381, 0.018916597589850426, 0.024584360420703888, 0.051934074610471725, -0.03491835296154022, -0.04457422345876694, 0.06970911473035812, 0.017906969413161278, -0.05537048727273941, 0.06888648122549057, 0.018783628940582275, 0.012544671073555946, -0.02326677367091179, -0.07268336415290833, -0.07773054391145706, 0.023728130385279655, -0.0091549726203084, 0.08447437733411789, -0.026682747527956963, -0.06762050837278366, -0.0012076667044311762, -0.06524593383073807, 0.008584322407841682, -0.019390564411878586, -0.06013505905866623, -0.01585807092487812, -0.06882055103778839, 0.01897462084889412, 0.044516779482364655, 0.04671576991677284, 0.03744601830840111, -0.001585967605933547, 0.052910324186086655, 0.08974413573741913, -0.09942317754030228, 0.030438365414738655, -0.05439973250031471, -0.006547756027430296, -0.036025214940309525, -0.03823702037334442, 0.11312904953956604, 0.08376094698905945, 0.012315847910940647, 0.0940665453672409, 0.025012021884322166, 0.027294320985674858, -0.03388216719031334, 0.06419650465250015, 0.08970080316066742, 0.03435395658016205, -0.0661533921957016, 0.02089666947722435, 0.05313403159379959, 0.01731160469353199, 0.09528009593486786, -0.015460298396646976, 0.03717430308461189, 0.08356599509716034, 0.0337497740983963, 0.04346727579832077, 0.04403533414006233, -0.03050786443054676, -0.062383413314819336, -0.0491490438580513, 0.06208052113652229, -0.0029254041146486998, 0.021808762103319168, -0.03977668657898903, -0.00010095890320371836, -0.0018478847341611981, 0.008371620438992977, -0.012602506205439568, -0.0029589966870844364, -0.10421059280633926, 0.05318431556224823, 0.07495825737714767, 0.07073143869638443, 0.11444398015737534, 0.0029442869126796722, -0.013786567375063896, 0.03908272087574005, 0.060869619250297546, 0.06664422154426575, -0.005343213677406311, 3.379289486566819e-33, -0.03649507462978363, -0.005196000449359417, 0.029986653476953506, -0.0020352324936538935, -0.014039725996553898, -0.016255825757980347, 0.018566636368632317, 0.004861402325332165, -0.0703723356127739, 0.07698947936296463, -0.015852971002459526, 0.010536160320043564, -0.0428725965321064, 0.048544082790613174, 0.0444268137216568, -0.05689389258623123, 0.0841945931315422, -0.033554933965206146, 0.015177560970187187, -0.02207918092608452, 0.01327163353562355, -0.021426495164632797, -0.04818502441048622, 0.023964984342455864, 0.02610757388174534, 0.03638564795255661, 0.03375313803553581, 0.06718580424785614, 0.03687720745801926, 0.05212511494755745, -0.007662582211196423, -0.08483581990003586, -0.006494056433439255, -0.00783604383468628, -0.04085919260978699, -0.05921618267893791, -0.06205533444881439, -0.05701850727200508, 0.01683054305613041, -0.0008081029518507421, -0.03200443834066391, 0.032842375338077545, -0.050206396728754044, -0.0872844010591507, -0.06511292606592178, -0.037224091589450836, 0.09900879859924316, 0.08347738534212112, 0.0479041263461113, 0.008161595091223717, -0.02963477373123169, -0.006441823672503233, 0.04320818558335304, -0.09588000923395157, -0.005539844278246164, -0.014319334179162979, 0.049207642674446106, -0.022023646160960197, -0.032618820667266846, -0.02960915118455887, 0.06945633888244629, 0.012576195411384106, 0.020621471107006073, 0.11317399144172668, 0.02396486885845661, 0.02959451451897621, 0.05916617438197136, -0.08257529884576797, -0.06517236679792404, -0.05389319732785225, -0.13870830833911896, -0.01000305451452732, 0.07803913950920105, -0.032725635915994644, -0.023292886093258858, -0.06459148228168488, 0.014196334406733513, -0.023884480819106102, 0.04779304563999176, -0.0029379818588495255, -0.026047825813293457, -0.02726711705327034, 0.04294970631599426, 0.05204348638653755, -0.05354474484920502, -0.09833695739507675, -0.06558075547218323, -0.01675090193748474, -0.025732582435011864, -0.038244232535362244, 0.07540657371282578, -0.08174258470535278, -0.029362373054027557, 0.014700671657919884, -0.060369573533535004, -3.639300755445047e-33, 0.0031200996600091457, -0.08296750485897064, 0.0660184770822525, -0.06137314811348915, 0.06385640054941177, -0.024695422500371933, 0.022956112399697304, 0.06715579330921173, 0.03791544958949089, 0.01702764630317688, 0.11500974744558334, -0.028730088844895363, -0.0363282784819603, 0.04574565589427948, -0.000865305308252573, 0.03350551053881645, -0.005562445614486933, 0.027375562116503716, 0.029291382059454918, -0.08352124691009521, 0.05288439616560936, 0.03317632898688316, 0.04194740951061249, -0.017364975064992905, 0.04263841733336449, 0.05472301319241524, 0.031004667282104492, 0.016630766913294792, 0.012754390016198158, 0.03690369799733162, -0.134001687169075, -0.06047360971570015, 0.04560333862900734, 0.042102716863155365, -0.0885104313492775, -0.03708473592996597, 0.04954589903354645, -0.030429771170020103, 0.015348431654274464, -0.013120943680405617, 0.04993952065706253, -0.010705134831368923, 0.12568344175815582, 0.0038354680873453617, -0.005373703315854073, -0.010392172262072563, 0.03874552622437477, -0.005448464769870043, 0.01590108312666416, 0.030423685908317566, -0.019050365313887596, -0.031593918800354004, 0.04912016913294792, 0.08720909059047699, 0.003949107602238655, 0.017207195982336998, 0.026721833273768425, -0.04145307466387749, 0.01226820144802332, -0.019311463460326195, 0.07985170930624008, 0.028411729261279106, -0.005395942833274603, 0.06707075238227844, -0.003691009944304824, 0.06240038573741913, -0.06228107586503029, 0.0066701872274279594, -0.07135938107967377, -0.038472894579172134, 0.0026564686559140682, -0.049368057399988174, -0.08273565769195557, -0.07895845919847488, -0.012465099804103374, -0.04309729486703873, 0.01129241194576025, -0.012888927012681961, -0.10898063331842422, -0.040098242461681366, 0.029696093872189522, -0.05698377266526222, -0.01632518321275711, -0.012124690227210522, 0.004784205462783575, 0.05723068118095398, 0.027661360800266266, 0.06545499712228775, 0.01902274414896965, 0.015089118853211403, -0.048557717353105545, 0.02426265925168991, -0.05039460211992264, 0.04768054187297821, 0.039540790021419525, -5.5534020049208266e-08, -0.05592983216047287, 0.03446615859866142, -0.038738567382097244, -0.09586751461029053, 0.019432170316576958, -0.07700260728597641, 0.009844508022069931, -0.048326872289180756, 0.0023948941379785538, 0.09771674871444702, 0.030574120581150055, -0.1018349900841713, 0.0033272497821599245, -0.07565375417470932, -0.03612634539604187, -0.06505239009857178, -0.09511857479810715, 0.012929634191095829, -0.052790574729442596, -0.013081835582852364, 0.06428495049476624, -0.05848004296422005, 0.0767960250377655, -0.038181304931640625, -0.05048747733235359, 0.026767853647470474, -0.12775224447250366, 0.0711159035563469, 0.009822063148021698, 0.0631263330578804, -0.005118849221616983, 0.04436172544956207, -0.0004445934318937361, -0.048570454120635986, -0.09810394793748856, -0.017896167933940887, -0.056788284331560135, 0.02274196594953537, 0.04884520173072815, 0.06488439440727234, 0.06924950331449509, -0.030724750831723213, -0.09138835221529007, 0.09546652436256409, 0.04316571354866028, -0.05527685955166817, -0.01856996677815914, -0.09778275340795517, 0.03314564749598503, 0.05575082078576088, 0.015440995804965496, -0.031097782775759697, -0.050652895122766495, -0.055059850215911865, -0.04094768688082695, 0.06069083511829376, 0.01418936438858509, 0.0363878570497036, -0.02386080101132393, 0.06258054822683334, 0.04381772130727768, -0.10582537949085236, -0.04821829870343208, 0.014279887080192566]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymongo\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# MongoDB connection parameters\n",
        "connection_string ='mongodb+srv://mosesmacharia084:qKQkJdvQOMRXOiO9@cluster0.gcck2ys.mongodb.net/'\n",
        "database_name = \"ebay_watch_data\"\n",
        "collection_name = \"watch_vec\"\n",
        "\n",
        "# Connect to MongoDB\n",
        "client = pymongo.MongoClient(connection_string)\n",
        "db = client[database_name]\n",
        "collection = db[collection_name]\n",
        "\n",
        "# Initialize SentenceTransformer model\n",
        "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Retrieve embeddings from MongoDB\n",
        "embeddings = []\n",
        "for document in collection.find({}, {\"_id\": 0, \"embedding\": 1}):\n",
        "    embeddings.append(document[\"embedding\"])\n",
        "\n",
        "# Convert embeddings to numpy array\n",
        "embeddings = np.array(embeddings)\n",
        "\n",
        "# Define a function to calculate cosine similarity\n",
        "def execute_mongodb_query(query_text):\n",
        "    # Encode the query text using Sentence Transformers\n",
        "    query_embedding = embedding_model.encode([query_text])[0]\n",
        "\n",
        "    # Calculate similarity scores\n",
        "    similarities = calculate_similarity(query_embedding, embeddings)\n",
        "\n",
        "    # Find the index of the most similar document\n",
        "    most_similar_index = np.argmax(similarities)\n",
        "\n",
        "    # Skip documents if necessary\n",
        "    skip_count = 0\n",
        "    for document in collection.find():\n",
        "        if skip_count == most_similar_index:\n",
        "            return document\n",
        "        skip_count += 1\n",
        "\n",
        "    return None\n",
        "\n",
        "# Example query\n",
        "query_text = \"Apple watches\"\n",
        "query_result = execute_mongodb_query(query_text)\n",
        "print(query_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCbhxIyoai0f",
        "outputId": "4c985c55-a55b-4e49-9f8d-b1ed20d6f1b9"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'_id': ObjectId('6601c72b4c67eb695bf7ae58'), 'input': 'Can you provide details about the For Apple Watch Silicone Band Strap 2 3 4 5 6 7 8 9 SE Sport 38/40/41/42/44/45mm?', 'output': 'The For Apple Watch Silicone Band Strap 2 3 4 5 6 7 8 9 SE Sport 38/40/41/42/44/45mm is New with tags and priced at $2.99. You can find more details on the product page: https://www.ebay.com/itm/Apple-Watch-Silicone-Band-Strap-2-3-4-5-6-7-8-9-SE-Sport-38-40-41-42-44-45mm-/235236675000?var=0', 'generated_output': '**Product name:** For Apple Watch Silicone Band Strap 2 3 4 5 6 7 8 9 SE Sport 38/40/41/42/44/45mm\\n\\n**Features:**\\n\\n* Made of high-quality silicone, soft and comfortable to wear.\\n* Secure stainless steel buckle, easy to wear and take off.\\n* Precise cut, perfect fit for your Apple Watch.\\n* Multiple colors to choose from, match your style.\\n\\n**Compatible models:**\\n\\n* Apple Watch Series 2/3/4/5/6/7/8/SE\\n* Apple Watch 38mm/40mm/41mm/42mm/44mm/45mm\\n\\n**Package includes:**\\n\\n* 1 x Silicone Watch Band\\n* 1 x Stainless Steel Buckle', 'embedding': [-0.05832396820187569, -0.0042482721619307995, 0.033612508326768875, -0.001134776510298252, 0.0022774229291826487, 0.01109651755541563, 0.10649506002664566, 0.0742076113820076, 0.016111057251691818, -0.060308732092380524, -0.007138147484511137, -0.07723986357450485, -0.009666328318417072, 0.007884854450821877, -0.06848081946372986, -0.01614990271627903, 0.005796804092824459, 0.010349463671445847, -0.024913113564252853, 0.017374077811837196, 0.051427241414785385, -0.037028174847364426, 0.02462356723845005, 0.07555117458105087, -0.08900249749422073, 0.04503566026687622, 0.03628537803888321, 0.008436515927314758, -0.04636557027697563, -0.029810944572091103, -0.05953407287597656, -0.06638757884502411, 0.024847710505127907, 0.07643535733222961, 0.01870892569422722, -0.03259376436471939, 0.03771422058343887, -0.057196442037820816, -0.1188538521528244, 0.020704232156276703, 0.035247258841991425, 0.012460267171263695, 0.0303114652633667, 0.07986843585968018, 0.021206768229603767, 0.10735630989074707, -0.0005962252616882324, 0.03751488775014877, -0.04697312042117119, 0.055398210883140564, -0.05226112902164459, -0.023144299164414406, 0.0028227672446519136, 0.010211343877017498, 0.0293574295938015, -0.02695981040596962, -0.006802419200539589, -0.002027988201007247, 0.05388753488659859, 0.02148418314754963, 0.12805208563804626, -0.07084134221076965, -0.045605115592479706, 0.05256018042564392, -0.05643603950738907, 0.02516014128923416, 0.00793655775487423, -0.025059815496206284, -0.0373343750834465, 0.007963466458022594, -0.02371269278228283, -0.03722291812300682, 0.06196565553545952, 0.03997685760259628, 0.04264553263783455, 0.10561085492372513, 0.05085970461368561, -0.05379943549633026, -0.02620682120323181, -0.04051973298192024, -0.09561832249164581, -0.062057238072156906, -0.029312066733837128, 0.061005882918834686, 0.07896456867456436, 0.008309118449687958, 0.009084858000278473, -0.049924079328775406, 0.022189201787114143, 0.013431532308459282, 0.006599923595786095, 0.061526473611593246, -0.02667868509888649, -0.08544204384088516, 0.016984811052680016, 0.06334583461284637, -0.004386870190501213, 0.08933017402887344, 0.02597186714410782, 0.07590525597333908, 0.023515168577432632, 0.03268126770853996, -0.0348079688847065, 0.08139929175376892, 0.029058584943413734, -0.04848606884479523, -0.03335076570510864, 0.021050911396741867, -0.0023203943856060505, 0.04929661005735397, -0.010943906381726265, 0.024030901491642, -0.06115312874317169, 0.045384135097265244, 0.04092859849333763, 0.053298771381378174, -0.029739635065197945, 0.15693672001361847, 0.12990999221801758, 0.03871675208210945, 0.03258224576711655, 0.04186106100678444, -0.07349416613578796, -0.03415228798985481, -0.09086453914642334, -0.006353917997330427, -0.07405760139226913, 1.650585453728485e-33, -0.008897298015654087, -0.005533095449209213, 0.04819841682910919, -0.050409287214279175, -0.07500270754098892, -0.08151574432849884, -0.048562150448560715, 0.013279118575155735, 0.03547592833638191, 0.04295492544770241, -0.0402202382683754, -0.06704279035329819, 0.02220178209245205, -0.005040603224188089, 0.1014549508690834, -0.050768837332725525, 0.010957962833344936, -0.06949051469564438, -0.013461066409945488, -0.053994208574295044, -0.0437152273952961, -0.02242300473153591, -0.018038257956504822, -0.015384089201688766, -0.002464024582877755, 0.06116370111703873, 0.04349683225154877, 0.05495285615324974, 0.07160742580890656, 0.009521005675196648, -0.02667025476694107, -0.05390458181500435, 0.017135104164481163, -0.0662839487195015, 0.029732704162597656, -0.05639707297086716, -0.022386912256479263, -0.006200498901307583, 0.00033300352515652776, 0.011950140818953514, 0.024382801726460457, 0.011142854578793049, 0.004962374456226826, -0.059229087084531784, 0.03389931097626686, -0.029896531254053116, 0.032514624297618866, 0.048695605248212814, 0.09847404807806015, -0.03132469207048416, -0.07766562700271606, -0.02597232535481453, 0.061659105122089386, -0.09461980313062668, -0.02384733222424984, -0.01931840181350708, 0.0036880194675177336, -0.014614068903028965, -0.04798615723848343, 0.0345647931098938, 0.000720761192496866, 0.006026660557836294, 0.07897094637155533, 0.06680773198604584, 0.0036342323292046785, 0.05101868137717247, 0.03823100030422211, -0.018558509647846222, -0.10091898590326309, -0.025753192603588104, -0.043177418410778046, 0.049965158104896545, 0.01770748943090439, -0.007225777488201857, -0.037954118102788925, -0.043800998479127884, 0.005541433580219746, -0.03671497106552124, 0.025430653244256973, -0.025563808158040047, -0.015458652749657631, -0.009361989796161652, 0.06548226624727249, 0.010448391549289227, -0.08772271871566772, 0.014268223196268082, 0.01724528707563877, -0.0772438570857048, 0.032044727355241776, -0.031741201877593994, 0.026984136551618576, -0.005242759361863136, -0.031699683517217636, -0.026912741363048553, -0.08741069585084915, -3.067398876541003e-33, 0.02492406964302063, -0.02710527367889881, 0.11124169081449509, -0.04048697650432587, 0.03939499706029892, -0.014364873059093952, -0.05653358995914459, 0.05006427690386772, 0.013790941797196865, 0.019587695598602295, 0.06611165404319763, -0.0539727546274662, -0.029833633452653885, -0.0030962000600993633, -0.016220247372984886, 0.052997931838035583, -0.05103381723165512, -0.022484395653009415, 0.03766660764813423, -0.02207339182496071, 0.10369791090488434, 0.038008350878953934, 0.06397789716720581, 0.015568253584206104, 0.045258380472660065, -0.017521819099783897, 0.06266389042139053, 0.0624566376209259, -0.048020754009485245, 0.03602280095219612, -0.04249758645892143, -0.04866703227162361, 0.005755933932960033, 0.06502117216587067, 0.005763451103121042, -0.052164316177368164, 0.04431821033358574, 0.0007296478725038469, 0.023832233622670174, -0.06435792148113251, -0.010914386250078678, 0.009025905281305313, 0.09692913293838501, -0.010521693155169487, -0.01709790527820587, 0.018837889656424522, 0.06625766307115555, 0.12816281616687775, -0.009455463849008083, -0.0355147123336792, -0.07604344934225082, -0.037990961223840714, -0.02031249739229679, 0.01924970932304859, -0.0893661305308342, 0.05220062658190727, -0.02280249074101448, 0.006259480025619268, -0.05064614862203598, -0.032968442887067795, 0.024993494153022766, 0.01723083294928074, 0.027819011360406876, 0.02612322010099888, 0.0633503720164299, -0.024499613791704178, -0.04216722026467323, 0.0061510964296758175, -0.0914590135216713, -0.0020629088394343853, 0.005822870880365372, 0.0029078302904963493, -0.07277193665504456, -0.046782560646533966, -0.0328352116048336, -0.07695572078227997, 0.04547228291630745, 0.05191054567694664, -0.09794764965772629, 0.07567483186721802, 0.07090829312801361, 0.07611354440450668, 0.006695662625133991, 0.005863229278475046, 0.0463067851960659, 0.08593384176492691, 0.06595837324857712, 0.11048726737499237, -0.005487525369971991, 0.056194376200437546, -0.06274311989545822, 0.02283165417611599, -0.010238109156489372, 0.04110384359955788, -0.13308127224445343, -4.5142616755811105e-08, 0.04915473237633705, -0.004460836295038462, -0.03684743121266365, -0.058409761637449265, -0.01695561222732067, -0.019847387447953224, -0.10508475452661514, -0.0716216191649437, 0.0552043579518795, 0.013203706592321396, -0.0241056177765131, -0.08147882670164108, -0.07529381662607193, 0.015562476590275764, -0.0933646634221077, -0.07728707045316696, -0.07495629787445068, 0.07912448793649673, -0.0031527436804026365, -0.021758118644356728, 0.0011192854726687074, -0.015442710369825363, 0.07233860343694687, -0.04186989739537239, -0.0007268421468324959, 0.051042694598436356, -0.10611434280872345, 0.06840009242296219, 0.03350870683789253, 0.052074771374464035, -0.019559981301426888, 0.017782168462872505, 0.0359402634203434, -0.04232531785964966, -0.02613019198179245, -0.08400408178567886, -0.08349918574094772, -0.028686627745628357, 0.035616420209407806, 0.09958190470933914, 0.07174316793680191, -0.045779984444379807, 0.007033997680991888, 0.06087809056043625, 0.029047144576907158, -0.07289501279592514, 0.04147991165518761, -0.025361230596899986, -0.0017684224294498563, 0.014353170990943909, 0.03228022903203964, -0.08922875672578812, 0.0008253256091848016, -0.01080654188990593, -0.10658542811870575, 0.003280371194705367, 0.0019572062883526087, -0.00418445048853755, -0.05336717516183853, 0.040342651307582855, 0.05333893001079559, -0.15753017365932465, -0.02561202459037304, 0.039302174001932144]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VdfF7mjQcg6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pymongo\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# MongoDB connection parameters\n",
        "connection_string ='mongodb+srv://mosesmacharia084:qKQkJdvQOMRXOiO9@cluster0.gcck2ys.mongodb.net/'\n",
        "database_name = \"ebay_watch_data\"\n",
        "collection_name = \"watch_vec\"\n",
        "\n",
        "# Connect to MongoDB\n",
        "client = pymongo.MongoClient(connection_string)\n",
        "db = client[database_name]\n",
        "collection = db[collection_name]\n",
        "\n",
        "# Initialize SentenceTransformer model\n",
        "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Retrieve embeddings from MongoDB\n",
        "embeddings = []\n",
        "for document in collection.find({}, {\"_id\": 0, \"embedding\": 1}):\n",
        "    embeddings.append(document[\"embedding\"])\n",
        "\n",
        "# Convert embeddings to numpy array\n",
        "embeddings = np.array(embeddings)\n",
        "\n",
        "# Define a function to calculate cosine similarity\n",
        "def calculate_similarity(query_embedding, embeddings):\n",
        "    similarities = cosine_similarity([query_embedding], embeddings)\n",
        "    return similarities[0]\n",
        "\n",
        "def execute_mongodb_query(query_text):\n",
        "    # Encode the query text using Sentence Transformers\n",
        "    query_embedding = embedding_model.encode([query_text])[0]\n",
        "\n",
        "    # Calculate similarity scores\n",
        "    similarities = calculate_similarity(query_embedding, embeddings)\n",
        "\n",
        "    # Find the index of the most similar document\n",
        "    most_similar_index = np.argmax(similarities)\n",
        "\n",
        "    # Skip documents if necessary\n",
        "    skip_count = 0\n",
        "    for document in collection.find():\n",
        "        if skip_count == most_similar_index:\n",
        "            return document\n",
        "        skip_count += 1\n",
        "\n",
        "    return None\n",
        "\n",
        "    # Retrieve the most similar document\n",
        "    most_similar_document = collection.find().skip(most_similar_index).limit(1)\n",
        "\n",
        "    return most_similar_document[0] if most_similar_document.count() > 0 else None\n",
        "\n",
        "# Accept query text from the end user\n",
        "query_text = input(\"Enter your query: \")\n",
        "\n",
        "# Execute the MongoDB query\n",
        "query_result = execute_mongodb_query(query_text)\n",
        "\n",
        "# Print the result\n",
        "print(query_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxniQNRBbkIx",
        "outputId": "481b44c6-dd74-40bf-84fd-24736f3d8e5a"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your query: casio\n",
            "{'_id': ObjectId('6601c7264c67eb695bf7ae2d'), 'input': 'Can you provide details about the Rolex Datejust 41 mm 126334 Wimbledon Jubilee NEW 2024 MARCH Slate Roman?', 'output': 'The Rolex Datejust 41 mm 126334 Wimbledon Jubilee NEW 2024 MARCH Slate Roman is New with tags and priced at $15795.0. You can find more details on the product page: https://www.ebay.com/itm/Rolex-Datejust-41-mm-126334-Wimbledon-Jubilee-NEW-2024-MARCH-Slate-Roman-/186301918295', 'generated_output': '**Model:** Rolex Datejust 41 mm 126334 Wimbledon Jubilee NEW 2024 MARCH Slate Roman\\n\\n**Reference:** 126334\\n\\n**Case:** Stainless steel, 41 mm\\n\\n**Bezel:** Fluted\\n\\n**Dial:** Slate Roman\\n\\n**Hands:** Rhodium-plated, Chromalight\\n\\n**Markers:** Roman\\n\\n**Crystal:** Sapphire, with cyclops lens over the date\\n\\n**Movement:** Automatic, Caliber 3235\\n\\n**Power Reserve:** Approximately 70 hours\\n\\n**Water Resistance:** 100 meters\\n\\n**Strap:** Jubilee bracelet with Oysterlock clasp\\n\\n**Price:** \\\\$10,550\\n\\n**Availability:** Available now at authorized Rolex dealers', 'embedding': [-0.09534884244203568, -0.0059840199537575245, 0.037650398910045624, -0.0807550922036171, -0.07215077430009842, 0.033029984682798386, -0.02156735584139824, 0.09182506799697876, -0.043292395770549774, -0.016780497506260872, -0.062307946383953094, -0.053659141063690186, -0.06939096003770828, 0.03611542657017708, -0.1037633940577507, -0.0798105001449585, 0.045792870223522186, -0.0047340402379632, -0.024781936779618263, 0.10115370899438858, 0.019193332642316818, -0.05587269738316536, -0.016618434339761734, 0.03332310914993286, 0.027989251539111137, 0.11405843496322632, -0.04407305270433426, 0.03488680347800255, 0.006819770205765963, -0.04101194441318512, -0.04318792372941971, 0.08067101240158081, 0.01030503585934639, -0.009491957724094391, 0.02026347629725933, -0.0034451615065336227, -0.0062621766701340675, 0.010510698892176151, 0.03905892372131348, -0.03272726759314537, -0.027151523157954216, -0.03254951164126396, -0.021211104467511177, 0.14951187372207642, 3.660537913674489e-05, 0.018104812130331993, 0.03163645416498184, 0.03814910352230072, -0.044982247054576874, 0.04086393117904663, -0.03311411663889885, -0.027723083272576332, 0.03842361271381378, -0.036093808710575104, 0.026935553178191185, 0.0431339256465435, -0.04699866473674774, -0.13143986463546753, 0.06818732619285583, -0.04089473560452461, -0.012056336738169193, -0.013589886017143726, -0.10247162729501724, 0.062059883028268814, -0.0406404510140419, -0.005700672976672649, -0.0019155051559209824, -0.06326128542423248, -0.020967481657862663, -0.02480560541152954, 0.04616650193929672, 0.038962945342063904, 0.08280874788761139, 0.0025880183093249798, 0.047107137739658356, 0.10744047164916992, 0.060795191675424576, -0.1214393824338913, 0.014940919354557991, -0.041063323616981506, -0.013823707588016987, -0.025550970807671547, -0.023815440014004707, 0.028357796370983124, 0.027539769187569618, -0.05614389851689339, 0.07940763980150223, 0.055720750242471695, 0.035215042531490326, -0.023541871458292007, 0.04709416255354881, 0.06967787444591522, -0.02670338936150074, -0.00015710377192590386, -0.04667523875832558, 0.021079987287521362, 0.04369160905480385, 0.0454217791557312, 0.037208035588264465, 0.10485266894102097, 0.042177923023700714, 0.03020636923611164, 0.01916891150176525, 0.027045058086514473, -0.032241787761449814, -0.014115525409579277, -0.0574965737760067, 0.07254908978939056, -0.06236478313803673, -0.08460023254156113, -0.03740781918168068, -0.012697471305727959, -0.07522474229335785, -0.04640240967273712, -0.046096716076135635, 0.02899639867246151, -0.05495604872703552, 0.04060731828212738, 0.07139260321855545, 0.002194345463067293, -0.0027798963710665703, -0.005815001204609871, -0.048579826951026917, -0.026005109772086143, -0.10657889395952225, 0.058590117841959, -0.02921941503882408, 4.513096766947117e-33, -0.03124087303876877, -0.02436019666492939, -0.020362451672554016, -0.015492822974920273, -0.053285565227270126, 0.007690795231610537, -0.011801822111010551, 0.04811236634850502, -0.03647231683135033, -0.027051130309700966, -0.004187314305454493, -0.0026460220105946064, -0.012165927328169346, -0.06932441145181656, 0.03422940522432327, -0.009101650677621365, 0.07424456626176834, 0.03325080871582031, -0.037866152822971344, -9.190182026941329e-05, -0.02581426501274109, -0.01012426521629095, 0.026383139193058014, 0.04002492129802704, -0.009708186611533165, 0.11416992545127869, 0.018877461552619934, 0.014784120954573154, 0.04619509354233742, 0.0675835832953453, 0.016046596691012383, -0.06076163053512573, -0.028526417911052704, -0.018218904733657837, 0.030639948323369026, 0.04457918554544449, -0.0978168174624443, -0.08005084097385406, 0.06057443842291832, -0.035778895020484924, -0.09904908388853073, 0.04201075807213783, -0.03593645617365837, -0.07002899795770645, -0.042885228991508484, -0.05339399352669716, -0.018796350806951523, 0.0571848601102829, 0.01791851967573166, 0.006118067540228367, -0.00693074194714427, 0.022409522905945778, -0.005770898889750242, -0.053690798580646515, -0.05562223866581917, -0.025330260396003723, -0.03191627934575081, -0.02492883801460266, -0.006032311823219061, 0.014907896518707275, 0.04086529463529587, 0.07542385160923004, 0.009226448833942413, 0.03796624764800072, 0.005298929288983345, 0.07779877632856369, 0.009259114041924477, -0.035493798553943634, -0.06762206554412842, 0.011663387529551983, -0.0434306375682354, -0.027134951204061508, 0.1042909324169159, 0.04222866892814636, 0.05365562066435814, -0.021373284980654716, 0.11566507816314697, -0.07696650922298431, -0.020601022988557816, -0.003826978150755167, -0.10838881880044937, 0.04573134705424309, 0.025974037125706673, -0.02129112370312214, -0.041731465607881546, -0.06385846436023712, 0.03572872281074524, 0.0188840813934803, 0.03253735974431038, 0.03458292782306671, 0.015610185451805592, -0.1208258718252182, -0.09261541813611984, 0.020885754376649857, -0.0677078440785408, -3.1857101788993584e-33, 0.01943304017186165, -0.061129968613386154, 0.0005787234986200929, 0.005392398219555616, -0.0015200652414932847, -0.014783981256186962, 0.029713042080402374, 0.1361522078514099, 0.08212480694055557, 0.0108990129083395, 0.058019544929265976, 0.028875010088086128, -0.06197916716337204, 0.021592825651168823, -0.02384796179831028, -0.004991813097149134, 0.0018349882448092103, -0.01718493178486824, -0.059314627200365067, 0.01894247531890869, 0.10919082164764404, 0.07653675228357315, -0.052707500755786896, 0.05875193700194359, 0.028314167633652687, 0.053226299583911896, 0.025226954370737076, -0.0045907627791166306, -0.02169767953455448, 0.03810090199112892, -0.04557613283395767, -0.05981818959116936, -0.037231363356113434, 0.06033220514655113, -0.04901408776640892, 0.018599707633256912, 0.12877394258975983, 0.018276991322636604, 0.010232587344944477, 0.03942080959677696, 0.0007588756270706654, 0.04317784681916237, 0.06195502355694771, 0.08569018542766571, 0.05696788430213928, 0.01751650497317314, 0.07776681333780289, 0.04588043689727783, 0.0949852392077446, 0.057530783116817474, -0.06572213023900986, 0.035447243601083755, 0.015487845055758953, 0.05675214156508446, 0.0003969470562878996, -0.016828961670398712, 0.007530611008405685, -0.019846204668283463, -0.010442527942359447, 0.013326301239430904, 0.05420282483100891, 0.02272338792681694, -0.011375929228961468, -0.016643324866890907, 0.07312777638435364, -0.005715218838304281, -0.04779140651226044, -0.03223910555243492, -0.05610797554254532, 0.01657283864915371, -0.05226854234933853, -0.028746608644723892, -0.04510771855711937, -0.05109582096338272, 0.040256332606077194, 0.028548629954457283, 0.05613080412149429, 0.007206300273537636, -0.020981881767511368, -0.024140814319252968, 0.055989015847444534, 0.01625451073050499, -0.007104137912392616, 0.07385290414094925, 0.07707763463258743, 0.036703210324048996, 0.07330060750246048, 0.050452012568712234, -0.07922030240297318, -0.06487347930669785, 0.01210043579339981, 0.05899346247315407, 0.012775457464158535, 0.026076318696141243, 0.04351899400353432, -6.087351067662894e-08, 0.012054410763084888, 0.06919996440410614, -0.018847942352294922, -0.004951773677021265, 0.02919623628258705, -0.03245942294597626, 0.027136534452438354, -0.052534881979227066, 0.057928234338760376, 0.028430292382836342, 0.09939216822385788, -0.05840937793254852, 0.005975483916699886, -0.129568412899971, -0.06603845953941345, 0.0020534058567136526, -0.15668174624443054, -0.002429397078230977, -0.07168211787939072, 0.012192672118544579, 0.06644602864980698, -0.033120691776275635, 0.09833379834890366, -0.027202919125556946, -0.012083284556865692, -0.06309110671281815, -0.020208174362778664, 0.034265417605638504, -0.05392640456557274, 0.02534157782793045, 0.0394328273832798, 0.01398448459804058, 0.057522308081388474, 0.004407579079270363, 0.029509712010622025, 0.003613625653088093, -0.08028537780046463, 0.06893739849328995, 0.028255198150873184, 0.040545832365751266, 0.005410888697952032, -0.07954948395490646, -0.11946945637464523, 0.06424811482429504, 0.07838114351034164, 0.005122743081301451, -0.031580716371536255, -0.014401670545339584, 0.011362185701727867, -0.04548085853457451, -0.024265022948384285, -0.015872515738010406, 0.030225349590182304, -0.01790153793990612, -0.03023223951458931, 0.06153900548815727, 0.029346786439418793, 0.0398925244808197, 0.004083088133484125, 0.003783199703320861, 0.03360052779316902, -0.1564721167087555, -0.0599026195704937, 0.03610211983323097]}\n"
          ]
        }
      ]
    },
    {
      "source": [
        "first_document = collection.find_one()\n",
        "print(first_document)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKEkv-gl25p8",
        "outputId": "fd06eb67-256d-487d-ba04-647422fca6c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'_id': ObjectId('6601c7204c67eb695bf7adef'), 'input': 'Can you provide details about the ROLEX MENS DATEJUST BLUE DIAL 18K WHITE GOLD & STAINLESS STEEL WATCH?', 'output': 'The ROLEX MENS DATEJUST BLUE DIAL 18K WHITE GOLD & STAINLESS STEEL WATCH is Pre-owned and priced at $4199.95. You can find more details on the product page: https://www.ebay.com/itm/ROLEX-MENS-DATEJUST-BLUE-DIAL-18K-WHITE-GOLD-STAINLESS-STEEL-WATCH-/173854683740', 'generated_output': \"**Model:** Rolex Datejust 126334\\n\\n**Case:** 36mm stainless steel case with fluted bezel and 18k white gold fluted crown\\n\\n**Dial:** Blue dial with applied gold hour markers and Roman numerals at 3, 6, and 9 o'clock\\n\\n**Hands:** Blued steel hands with luminous material\\n\\n**Movement:** Automatic Rolex Caliber 3235 with a power reserve of approximately 70 hours\\n\\n**Strap:** Oyster bracelet with folding clasp\\n\\n**Water Resistance:** 100 meters\\n\\n**Price:** $8,250\\n\\nThe Rolex Datejust is one of the most iconic and popular watches in the world. It is known for its timeless design, impeccable craftsmanship, and high quality materials. The 126334 is a particularly attractive version of the Datejust, with its blue dial, 18k white gold fluted bezel, and stainless steel case. This watch is perfect for anyone looking for a stylish and luxurious timepiece that will last a lifetime.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_4Sw33QA2JyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo import MongoClient\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# MongoDB connection string\n",
        "connection_string = 'mongodb+srv://mosesmacharia084:qKQkJdvQOMRXOiO9@cluster0.gcck2ys.mongodb.net/'\n",
        "\n",
        "# Database and collection names\n",
        "database_name = \"ebay_watch_data\"\n",
        "collection_name = \"embedding\"\n",
        "\n",
        "# Initialize SentenceTransformer model\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Connect to MongoDB\n",
        "client = MongoClient(connection_string)\n",
        "db = client[database_name]\n",
        "collection = db[collection_name]\n",
        "\n",
        "# Retrieve embeddings from MongoDB\n",
        "embeddings = []\n",
        "for document in collection.find({}, {\"_id\": 0, \"embedding\": 1}):\n",
        "    embeddings.append(document[\"embedding\"])\n",
        "\n",
        "# Convert embeddings to numpy array\n",
        "embeddings = np.array(embeddings)\n",
        "\n",
        "# Define a function to calculate cosine similarity\n",
        "def calculate_similarity(query_embedding, embeddings):\n",
        "    similarities = cosine_similarity([query_embedding], embeddings)\n",
        "    return similarities[0]\n",
        "\n",
        "# Example query\n",
        "query = \"Can you provide details about the Rolex Datejust 126300 Silver Oyster Bracelet with Silver Bezel?\"\n",
        "\n",
        "# Encode the query\n",
        "query_embedding = model.encode([query])[0]\n",
        "\n",
        "# Calculate similarity scores\n",
        "similarities = calculate_similarity(query_embedding, embeddings)\n",
        "\n",
        "# Find the index of the most similar document\n",
        "most_similar_index = np.argmax(similarities)\n",
        "most_similar_document = collection.find_one({\"embedding\": embeddings[most_similar_index].tolist()})\n",
        "# Retrieve the most similar document\n",
        "#most_similar_document = collection.find().skip(most_similar_index).limit(1)\n",
        "\n",
        "# Filter out unwanted fields\n",
        "filtered_document = {key: value for key, value in most_similar_document.items() if key not in ['_id', 'embedding']}\n",
        "\n",
        "# Print the filtered document\n",
        "print(\"Most similar document:\")\n",
        "print(filtered_document)\n",
        "\n",
        "# Print the most similar document\n",
        "#print(\"Most similar document:\")\n",
        "#print(most_similar_document)\n",
        "\n",
        "# Close MongoDB connection\n",
        "client.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00c963df-3b58-487f-a3d8-182a7d3ebb79",
        "id": "MIRwiWTj2Kr5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most similar document:\n",
            "{'input': 'Can you provide details about the Rolex Datejust 126300 Silver Oyster Bracelet with Silver Bezel?', 'generated_output': 'The Rolex Datejust 126300 is a stainless steel watch with a silver dial and a silver bezel. It is powered by the Rolex Caliber 3235 movement, which has a power reserve of approximately 70 hours. The watch has a water resistance of 100 meters.', 'output_from_database': 'The Rolex Datejust 126300 Silver Oyster Bracelet with Silver Bezel is New with tags and priced at $990.0. You can find more details on the product page: https://www.ebay.com/itm/Rolex-Datejust-126300-Silver-Oyster-Bracelet-Silver-Bezel-/386882694335'}\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# MongoDB connection string\n",
        "connection_string = 'mongodb+srv://mosesmacharia084:qKQkJdvQOMRXOiO9@cluster0.gcck2ys.mongodb.net/'\n",
        "\n",
        "# Database and collection names\n",
        "database_name = \"ebay_watch_data\"\n",
        "collection_name = \"embedded\"\n",
        "\n",
        "# Initialize SentenceTransformer model\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Connect to MongoDB\n",
        "client = MongoClient(connection_string)\n",
        "db = client[database_name]\n",
        "collection = db[collection_name]\n",
        "\n",
        "# Retrieve embeddings from MongoDB\n",
        "embeddings = []\n",
        "for document in collection.find({}, {\"_id\": 0, \"embedding\": 1}):  # Replace \"embedded\" with the correct key name\n",
        "    embeddings.append(document[\"embedding\"])\n",
        "\n",
        "# Convert embeddings to numpy array\n",
        "embeddings = np.array(embeddings)\n",
        "\n",
        "# Define a function to calculate cosine similarity\n",
        "def calculate_similarity(query_embedding, embeddings):\n",
        "    similarities = cosine_similarity([query_embedding], embeddings)\n",
        "    return similarities[0]\n",
        "\n",
        "# Example query\n",
        "query = \"Can you provide details about the Rolex Datejust 126300 Silver Oyster Bracelet with Silver Bezel?\"\n",
        "\n",
        "# Encode the query\n",
        "query_embedding = model.encode([query])[0]\n",
        "\n",
        "# Calculate similarity scores\n",
        "similarities = calculate_similarity(query_embedding, embeddings)\n",
        "\n",
        "# Find the"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "XRsXGwP9nKkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import params\n",
        "from langchain.vectorstores import MongoDBAtlasVectorSearch\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
        "import warnings"
      ],
      "metadata": {
        "id": "P7BDCp3k9FWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install params"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "K_Clvyn5-K8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "warnings"
      ],
      "metadata": {
        "id": "5g6vH80WBL7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pymongo import MongoClient\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# MongoDB connection parameters\n",
        "connection_string = 'mongodb+srv://mosesmacharia084:qKQkJdvQOMRXOiO9@cluster0.gcck2ys.mongodb.net/'\n",
        "database_name = \"ebay_watch_data\"\n",
        "watches_collection_name = \"watches\"\n",
        "embedded_collection_name = \"embedded\"\n",
        "\n",
        "# Initialize SentenceTransformer model\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Connect to MongoDB\n",
        "client = MongoClient(connection_string)\n",
        "db = client[database_name]\n",
        "watches_collection = db[watches_collection_name]\n",
        "embedded_collection = db[embedded_collection_name]\n",
        "\n",
        "# Retrieve data from the watches collection\n",
        "watches_data = watches_collection.find({})\n",
        "\n",
        "# Embed and vectorize text data\n",
        "for watch in watches_data:\n",
        "    # Convert _id to string\n",
        "    watch['_id'] = str(watch['_id'])\n",
        "\n",
        "    # Convert all values to strings\n",
        "    watch = {k: str(v) for k, v in watch.items()}\n",
        "\n",
        "    concatenated_text = ' '.join(watch.values())\n",
        "    embedding = model.encode([concatenated_text])[0]\n",
        "\n",
        "    # Store the original data along with the embedding\n",
        "    watch[\"embedding\"] = embedding.tolist()\n",
        "\n",
        "    # Insert the document into the embedded collection\n",
        "    embedded_collection.insert_one(watch)\n",
        "\n",
        "#print(\"Embeddings stored in the 'embedded' collection.\")\n"
      ],
      "metadata": {
        "id": "b1KrHNsvN4V0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "watches_data = watches_collection.find({})\n",
        "for watch in watches_data:\n",
        "    print(watch)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "efqzDDuAOZJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "for watch in watches_data:\n",
        "    # Convert _id to string\n",
        "    watch['_id'] = str(watch['_id'])\n",
        "\n",
        "    # Convert all values to strings\n",
        "    watch = {k: str(v) for k, v in watch.items()}\n",
        "\n",
        "    concatenated_text = ' '.join(watch.values())\n",
        "    embedding = model.encode([concatenated_text])[0]"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "nJAlqCDcOkmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass, os, pymongo, pprint\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
        "#from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from pymongo import MongoClient"
      ],
      "metadata": {
        "id": "ZtL5z-xQV3Uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install langchain-mongodb"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "SCIBjH40WCKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "class SentenceTransformer:\n",
        "    # ... existing code\n",
        "\n",
        "    def embed_query(self, query):\n",
        "        \"\"\"\n",
        "        Embeds the given query using the SentenceTransformer model.\n",
        "\n",
        "        :param query: The query to embed.\n",
        "        :return: The embedding of the query.\n",
        "        \"\"\"\n",
        "        return self.encode([query])[0]"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "qeUNpXjFi1T5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymongo\n",
        "!pip install sentence-transformers\n"
      ],
      "metadata": {
        "id": "IN0chtownqjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "a-CbeVbKokF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pymongo\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "from langchain.llms import GooglePalm\n",
        "\n",
        "# MongoDB connection parameters\n",
        "connection_string ='mongodb+srv://mosesmacharia084:qKQkJdvQOMRXOiO9@cluster0.gcck2ys.mongodb.net/'\n",
        "database_name = \"ebay_watch_data\"\n",
        "collection_name = \"watch_vec\"\n",
        "\n",
        "# Connect to MongoDB\n",
        "client = pymongo.MongoClient(connection_string)\n",
        "db = client[database_name]\n",
        "collection = db[collection_name]\n",
        "\n",
        "# Initialize SentenceTransformer model\n",
        "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Retrieve embeddings from MongoDB\n",
        "embeddings = []\n",
        "for document in collection.find({}, {\"_id\": 0, \"embedding\": 1}):\n",
        "    embeddings.append(document[\"embedding\"])\n",
        "\n",
        "# Convert embeddings to numpy array\n",
        "embeddings = np.array(embeddings)\n",
        "\n",
        "# Define a function to calculate cosine similarity\n",
        "def calculate_similarity(query_embedding, embeddings):\n",
        "    similarities = cosine_similarity([query_embedding], embeddings)\n",
        "    return similarities[0]\n",
        "\n",
        "def execute_mongodb_query(query_text):\n",
        "    # Encode the query text using Sentence Transformers\n",
        "    query_embedding = embedding_model.encode([query_text])[0]\n",
        "\n",
        "    # Calculate similarity scores\n",
        "    similarities = calculate_similarity(query_embedding, embeddings)\n",
        "\n",
        "    # Find the index of the most similar document\n",
        "    most_similar_index = np.argmax(similarities)\n",
        "    # Skip documents if necessary\n",
        "    skip_count = 0\n",
        "    for document in collection.find():\n",
        "        if skip_count == most_similar_index:\n",
        "            return document\n",
        "        skip_count += 1\n",
        "\n",
        "    return None\n",
        "    # Retrieve the most similar document\n",
        "    most_similar_document = collection.find().skip(most_similar_index).limit(1)\n",
        "\n",
        "    return most_similar_document[0] if most_similar_document.count() > 0 else None\n",
        "\n",
        "def optimize_text_with_googlepalm(text):\n",
        "    # Initialize GooglePalm language model\n",
        "    api_key ='AIzaSyAPKvCTDopzRha-V6VMkDMuoaiVCc9YdQE'\n",
        "    palm = GooglePalm(google_api_key=api_key, temperature=0.2)\n",
        "\n",
        "    # Generate optimized text\n",
        "    optimized_text = palm.predict(text)\n",
        "\n",
        "    return optimized_text\n",
        "\n",
        "# Ask the user to input the query text\n",
        "query_text = input(\"Enter your query: \")\n",
        "\n",
        "# Execute the MongoDB query\n",
        "query_result = execute_mongodb_query(query_text)\n",
        "\n",
        "# Optimize the text using GooglePalm\n",
        "optimized_text = optimize_text_with_googlepalm(query_result)\n",
        "\n",
        "# Print the optimized text\n",
        "print(optimized_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "OeDYxA9adOdf",
        "outputId": "d1501c01-6578-4e39-e25d-f68400f61cb7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your query: Brand new Rolex watch\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "Need to determine which default deprecation schedule to use. within ?? minor releases",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-dcebe6b50045>\u001b[0m in \u001b[0;36m<cell line: 72>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# Optimize the text using GooglePalm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0moptimized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize_text_with_googlepalm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# Print the optimized text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-dcebe6b50045>\u001b[0m in \u001b[0;36moptimize_text_with_googlepalm\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# Initialize GooglePalm language model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'AIzaSyAPKvCTDopzRha-V6VMkDMuoaiVCc9YdQE'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mpalm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGooglePalm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgoogle_api_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# Generate optimized text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwarned\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_caller_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                         \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36memit_warning\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;34m\"\"\"Emit the warning.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             warn_deprecated(\n\u001b[0m\u001b[1;32m    118\u001b[0m                 \u001b[0msince\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_message\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarn_deprecated\u001b[0;34m(since, message, name, alternative, alternative_import, pending, obj_type, addendum, removal)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mremoval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mremoval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"in {removal}\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mremoval\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"within ?? minor releases\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             raise NotImplementedError(\n\u001b[0m\u001b[1;32m    338\u001b[0m                 \u001b[0;34mf\"Need to determine which default deprecation schedule to use. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;34mf\"{removal}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Need to determine which default deprecation schedule to use. within ?? minor releases"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymongo\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "from langchain.llms import GooglePalm\n",
        "\n",
        "# MongoDB connection parameters\n",
        "connection_string ='mongodb+srv://mosesmacharia084:qKQkJdvQOMRXOiO9@cluster0.gcck2ys.mongodb.net/'\n",
        "database_name = \"ebay_watch_data\"\n",
        "collection_name = \"watch_vec\"\n",
        "\n",
        "# Connect to MongoDB\n",
        "client = pymongo.MongoClient(connection_string)\n",
        "db = client[database_name]\n",
        "collection = db[collection_name]\n",
        "\n",
        "# Initialize SentenceTransformer model\n",
        "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Retrieve embeddings from MongoDB\n",
        "embeddings = []\n",
        "for document in collection.find({}, {\"_id\": 0, \"embedding\": 1}):\n",
        "    embeddings.append(document[\"embedding\"])\n",
        "\n",
        "# Convert embeddings to numpy array\n",
        "embeddings = np.array(embeddings)\n",
        "\n",
        "# Define a function to calculate cosine similarity\n",
        "def calculate_similarity(query_embedding, embeddings):\n",
        "    similarities = cosine_similarity([query_embedding], embeddings)\n",
        "    return similarities[0]\n",
        "\n",
        "def execute_mongodb_query(query_text):\n",
        "    # Encode the query text using Sentence Transformers\n",
        "    query_embedding = embedding_model.encode([query_text])[0]\n",
        "\n",
        "    # Calculate similarity scores\n",
        "    similarities = calculate_similarity(query_embedding, embeddings)\n",
        "\n",
        "    # Find the index of the most similar document\n",
        "    most_similar_index = np.argmax(similarities)\n",
        "    # Find the index of the most similar document\n",
        "    most_similar_index = np.argmax(similarities)\n",
        "    # Skip documents if necessary\n",
        "    skip_count = 0\n",
        "    for document in collection.find():\n",
        "        if skip_count == most_similar_index:\n",
        "            return document\n",
        "        skip_count += 1\n",
        "    # Retrieve the most similar document\n",
        "    most_similar_document = collection.find().skip(most_similar_index).limit(1)\n",
        "\n",
        "    return most_similar_document[0] if most_similar_document.count() > 0 else None\n",
        "\n",
        "def optimize_text_with_googlepalm(text):\n",
        "    # Initialize GooglePalm language model\n",
        "    api_key ='AIzaSyAPKvCTDopzRha-V6VMkDMuoaiVCc9YdQE'\n",
        "    palm = GooglePalm(google_api_key=api_key, temperature=0.2)\n",
        "\n",
        "    # Generate optimized text\n",
        "    optimized_text = palm.predict(text)\n",
        "\n",
        "    return optimized_text\n",
        "\n",
        "# Ask the user to input the query text\n",
        "query_text = input(\"Enter your query: \")\n",
        "\n",
        "# Execute the MongoDB query\n",
        "query_result = execute_mongodb_query(query_text)\n",
        "\n",
        "# Optimize the text using GooglePalm\n",
        "if query_result:\n",
        "    optimized_text = optimize_text_with_googlepalm(query_result)\n",
        "    print(\"Optimized text:\", optimized_text)\n",
        "else:\n",
        "    print(\"No results found for the query.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "Lm9FKOZ5qCNU",
        "outputId": "4c61c5c7-1a05-46ca-e8a1-a3965f9067c2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your query: Rolex\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Argument `prompt` is expected to be a string. Instead found <class 'dict'>. If you want to run the LLM on multiple prompts, use `generate` instead.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-021813afcdcb>\u001b[0m in \u001b[0;36m<cell line: 72>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# Optimize the text using GooglePalm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mquery_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0moptimized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize_text_with_googlepalm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Optimized text:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimized_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-021813afcdcb>\u001b[0m in \u001b[0;36moptimize_text_with_googlepalm\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# Generate optimized text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0moptimized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpalm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moptimized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, text, stop, **kwargs)\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m             \u001b[0m_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0.1.7\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malternative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"invoke\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremoval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.2.0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, prompt, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;34m\"\"\"Check Cache and run the LLM on the given prompt and input.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1023\u001b[0m                 \u001b[0;34m\"Argument `prompt` is expected to be a string. Instead found \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m                 \u001b[0;34mf\"{type(prompt)}. If you want to run the LLM on multiple prompts, use \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Argument `prompt` is expected to be a string. Instead found <class 'dict'>. If you want to run the LLM on multiple prompts, use `generate` instead."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymongo\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "from langchain.llms import GooglePalm\n",
        "\n",
        "# MongoDB connection parameters\n",
        "connection_string ='mongodb+srv://mosesmacharia084:qKQkJdvQOMRXOiO9@cluster0.gcck2ys.mongodb.net/'\n",
        "database_name = \"ebay_watch_data\"\n",
        "collection_name = \"watch_vec\"\n",
        "\n",
        "# Connect to MongoDB\n",
        "client = pymongo.MongoClient(connection_string)\n",
        "db = client[database_name]\n",
        "collection = db[collection_name]\n",
        "\n",
        "# Initialize SentenceTransformer model\n",
        "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Retrieve embeddings from MongoDB\n",
        "embeddings = []\n",
        "for document in collection.find({}, {\"_id\": 0, \"embedding\": 1}):\n",
        "    embeddings.append(document[\"embedding\"])\n",
        "\n",
        "# Convert embeddings to numpy array\n",
        "embeddings = np.array(embeddings)\n",
        "\n",
        "# Define a function to calculate cosine similarity\n",
        "def calculate_similarity(query_embedding, embeddings):\n",
        "    similarities = cosine_similarity([query_embedding], embeddings)\n",
        "    return similarities[0]\n",
        "\n",
        "def execute_mongodb_query(query_text):\n",
        "    # Encode the query text using Sentence Transformers\n",
        "    query_embedding = embedding_model.encode([query_text])[0]\n",
        "\n",
        "    # Calculate similarity scores\n",
        "    similarities = calculate_similarity(query_embedding, embeddings)\n",
        "\n",
        "    # Find the index of the most similar document\n",
        "    most_similar_index = np.argmax(similarities)\n",
        "    # Find the index of the most similar document\n",
        "    most_similar_index = np.argmax(similarities)\n",
        "    # Skip documents if necessary\n",
        "    skip_count = 0\n",
        "    for document in collection.find():\n",
        "        if skip_count == most_similar_index:\n",
        "            return document\n",
        "        skip_count += 1\n",
        "    # Retrieve the most similar document\n",
        "    most_similar_document = collection.find().skip(most_similar_index).limit(1)\n",
        "\n",
        "    return most_similar_document[0] if most_similar_document.count() > 0 else None\n",
        "\n",
        "def optimize_text_with_googlepalm(text):\n",
        "    # Initialize GooglePalm language model\n",
        "    api_key ='AIzaSyAPKvCTDopzRha-V6VMkDMuoaiVCc9YdQE'\n",
        "    palm = GooglePalm(google_api_key=api_key, temperature=0.2)\n",
        "\n",
        "    # Generate optimized text\n",
        "    optimized_text = palm.predict(document)\n",
        "\n",
        "    return optimized_text\n",
        "\n",
        "# Ask the user to input the query text\n",
        "query_text = input(\"Enter your query: \")\n",
        "\n",
        "# Execute the MongoDB query\n",
        "query_result = execute_mongodb_query(query_text)\n",
        "\n",
        "# Optimize the text using GooglePalm\n",
        "if query_result:\n",
        "    optimized_text = optimize_text_with_googlepalm(query_result[\"document\"])\n",
        "    print(\"Optimized text:\", optimized_text)\n",
        "else:\n",
        "    print(\"No results found for the query.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "9r4zS1UxrJW2",
        "outputId": "194e1512-a513-4012-df52-8c19d4d36252"
      },
      "execution_count": 10,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your query: rolex watches\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'document'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-80de2fc38a4c>\u001b[0m in \u001b[0;36m<cell line: 72>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# Optimize the text using GooglePalm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mquery_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0moptimized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize_text_with_googlepalm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"document\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Optimized text:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimized_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'document'"
          ]
        }
      ]
    }
  ]
}